{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b2c3d4-0002-0001-0001-000000000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b2c3d4-0002-0001-0001-000000000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"BAAI/bge-base-en-v1.5\"\n",
    "BATCH_SIZE = 64\n",
    "N_WORKERS = cpu_count()\n",
    "SAVE_EVERY = 1_000  # Save checkpoint every N articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b2c3d4-0002-0001-0001-000000000003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,748,719 articles\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>publishedDate</th>\n",
       "      <th>publisher</th>\n",
       "      <th>title</th>\n",
       "      <th>image</th>\n",
       "      <th>site</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>window_from</th>\n",
       "      <th>window_to</th>\n",
       "      <th>page</th>\n",
       "      <th>title_anon</th>\n",
       "      <th>text_anon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APLT</td>\n",
       "      <td>2025-01-28 17:30:00</td>\n",
       "      <td>Accesswire</td>\n",
       "      <td>Class Action Filed Against Applied Therapeutic...</td>\n",
       "      <td>https://images.financialmodelingprep.com/news/...</td>\n",
       "      <td>accessnewswire.com</td>\n",
       "      <td>NEW YORK, NY / ACCESS Newswire / January 28, 2...</td>\n",
       "      <td>https://www.accessnewswire.com/newsroom/en/bus...</td>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>2025-02-21</td>\n",
       "      <td>1</td>\n",
       "      <td>Class Action Filed Against __TARGET__ (__TARGE...</td>\n",
       "      <td>NEW YORK, NY / __OTHER__ / January 28, 2025 / ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2021-08-25 23:42:48</td>\n",
       "      <td>Benzinga</td>\n",
       "      <td>Apple Commits To Shoring Up Supply Chain Secur...</td>\n",
       "      <td>https://images.financialmodelingprep.com/news/...</td>\n",
       "      <td>benzinga.com</td>\n",
       "      <td>Apple Inc (NASDAQ: AAPL) is set to create a pr...</td>\n",
       "      <td>https://www.benzinga.com/news/21/08/22668742/a...</td>\n",
       "      <td>2021-08-11</td>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>0</td>\n",
       "      <td>__OTHER__ Commits To Shoring Up Supply Chain S...</td>\n",
       "      <td>__OTHER__ Inc (__OTHER__: __OTHER__) is set to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WDC</td>\n",
       "      <td>2025-10-23 11:05:51</td>\n",
       "      <td>Zacks Investment Research</td>\n",
       "      <td>Western Digital (WDC) Expected to Beat Earning...</td>\n",
       "      <td>https://images.financialmodelingprep.com/news/...</td>\n",
       "      <td>zacks.com</td>\n",
       "      <td>Western Digital (WDC) possesses the right comb...</td>\n",
       "      <td>https://www.zacks.com/stock/news/2775286/weste...</td>\n",
       "      <td>2025-10-19</td>\n",
       "      <td>2025-11-18</td>\n",
       "      <td>0</td>\n",
       "      <td>__TARGET__ (__TARGET__) Expected to __OTHER__ ...</td>\n",
       "      <td>__TARGET__ (__TARGET__) possesses the right co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2025-07-17 17:10:12</td>\n",
       "      <td>Bloomberg Markets and Finance</td>\n",
       "      <td>Netflix Reports Results | Closing Bell</td>\n",
       "      <td>https://images.financialmodelingprep.com/news/...</td>\n",
       "      <td>youtube.com</td>\n",
       "      <td>Comprehensive cross-platform coverage of the U...</td>\n",
       "      <td>https://www.youtube.com/watch?v=hvlxOAoLEJ4</td>\n",
       "      <td>2025-06-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>0</td>\n",
       "      <td>__TARGET__ Reports Results | Closing Bell</td>\n",
       "      <td>Comprehensive cross-platform coverage of the U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-30 16:37:10</td>\n",
       "      <td>NYTimes</td>\n",
       "      <td>Amazon Reports $143.3 Billion in Revenue for F...</td>\n",
       "      <td>https://images.financialmodelingprep.com/news/...</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>The company also reported that profit more tha...</td>\n",
       "      <td>https://www.nytimes.com/2024/04/30/technology/...</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>2024-05-27</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon Reports $143.3 Billion in Revenue for F...</td>\n",
       "      <td>The company also reported that profit more tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol        publishedDate                      publisher  \\\n",
       "0   APLT  2025-01-28 17:30:00                     Accesswire   \n",
       "1   MSFT  2021-08-25 23:42:48                       Benzinga   \n",
       "2    WDC  2025-10-23 11:05:51      Zacks Investment Research   \n",
       "3   NFLX  2025-07-17 17:10:12  Bloomberg Markets and Finance   \n",
       "4   AMZN  2024-04-30 16:37:10                        NYTimes   \n",
       "\n",
       "                                               title  \\\n",
       "0  Class Action Filed Against Applied Therapeutic...   \n",
       "1  Apple Commits To Shoring Up Supply Chain Secur...   \n",
       "2  Western Digital (WDC) Expected to Beat Earning...   \n",
       "3             Netflix Reports Results | Closing Bell   \n",
       "4  Amazon Reports $143.3 Billion in Revenue for F...   \n",
       "\n",
       "                                               image                site  \\\n",
       "0  https://images.financialmodelingprep.com/news/...  accessnewswire.com   \n",
       "1  https://images.financialmodelingprep.com/news/...        benzinga.com   \n",
       "2  https://images.financialmodelingprep.com/news/...           zacks.com   \n",
       "3  https://images.financialmodelingprep.com/news/...         youtube.com   \n",
       "4  https://images.financialmodelingprep.com/news/...         nytimes.com   \n",
       "\n",
       "                                                text  \\\n",
       "0  NEW YORK, NY / ACCESS Newswire / January 28, 2...   \n",
       "1  Apple Inc (NASDAQ: AAPL) is set to create a pr...   \n",
       "2  Western Digital (WDC) possesses the right comb...   \n",
       "3  Comprehensive cross-platform coverage of the U...   \n",
       "4  The company also reported that profit more tha...   \n",
       "\n",
       "                                                 url window_from   window_to  \\\n",
       "0  https://www.accessnewswire.com/newsroom/en/bus...  2025-01-22  2025-02-21   \n",
       "1  https://www.benzinga.com/news/21/08/22668742/a...  2021-08-11  2021-09-10   \n",
       "2  https://www.zacks.com/stock/news/2775286/weste...  2025-10-19  2025-11-18   \n",
       "3        https://www.youtube.com/watch?v=hvlxOAoLEJ4  2025-06-21  2025-07-21   \n",
       "4  https://www.nytimes.com/2024/04/30/technology/...  2024-04-27  2024-05-27   \n",
       "\n",
       "   page                                         title_anon  \\\n",
       "0     1  Class Action Filed Against __TARGET__ (__TARGE...   \n",
       "1     0  __OTHER__ Commits To Shoring Up Supply Chain S...   \n",
       "2     0  __TARGET__ (__TARGET__) Expected to __OTHER__ ...   \n",
       "3     0          __TARGET__ Reports Results | Closing Bell   \n",
       "4     1  Amazon Reports $143.3 Billion in Revenue for F...   \n",
       "\n",
       "                                           text_anon  \n",
       "0  NEW YORK, NY / __OTHER__ / January 28, 2025 / ...  \n",
       "1  __OTHER__ Inc (__OTHER__: __OTHER__) is set to...  \n",
       "2  __TARGET__ (__TARGET__) possesses the right co...  \n",
       "3  Comprehensive cross-platform coverage of the U...  \n",
       "4  The company also reported that profit more tha...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_parquet(\"data/all_the_news_anon.pqt\")\n",
    "print(f\"{len(news):,} articles\")\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1b2c3d4-0002-0001-0001-000000000004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 2 duplicate (url, symbol) pairs\n",
      "Found 9,998 existing embeddings\n",
      "1,738,719 articles to embed\n"
     ]
    }
   ],
   "source": [
    "# Check for and drop duplicate (url, symbol) pairs\n",
    "n_dups = news.duplicated(subset=[\"url\", \"symbol\"]).sum()\n",
    "if n_dups > 0:\n",
    "    print(f\"Dropping {n_dups:,} duplicate (url, symbol) pairs\")\n",
    "    news = news.drop_duplicates(subset=[\"url\", \"symbol\"], keep=\"first\")\n",
    "\n",
    "# Check for existing embeddings to skip\n",
    "EMBEDDINGS_PATH = \"data/news_embeddings.pqt\"\n",
    "try:\n",
    "    existing = pd.read_parquet(EMBEDDINGS_PATH)\n",
    "    already_done = set(zip(existing[\"url\"], existing[\"symbol\"]))\n",
    "    print(f\"Found {len(already_done):,} existing embeddings\")\n",
    "except FileNotFoundError:\n",
    "    already_done = set()\n",
    "    print(\"No existing embeddings found\")\n",
    "\n",
    "# Filter to only new articles\n",
    "news[\"_key\"] = list(zip(news[\"url\"], news[\"symbol\"]))\n",
    "to_embed = news[~news[\"_key\"].isin(already_done)].copy()\n",
    "to_embed.drop(columns=[\"_key\"], inplace=True)\n",
    "news.drop(columns=[\"_key\"], inplace=True)\n",
    "print(f\"{len(to_embed):,} articles to embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b2c3d4-0002-0001-0001-000000000005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg length: 603 chars\n"
     ]
    }
   ],
   "source": [
    "# Combine title + text for embedding\n",
    "texts = (to_embed[\"title_anon\"].fillna(\"\") + \" \" + to_embed[\"text_anon\"].fillna(\"\")).str.strip().tolist()\n",
    "urls = to_embed[\"url\"].tolist()\n",
    "symbols = to_embed[\"symbol\"].tolist()\n",
    "print(f\"Avg length: {np.mean([len(t) for t in texts]):.0f} chars\")\n",
    "\n",
    "# Split into chunks for workers\n",
    "def chunk_list(lst: list, n_chunks: int) -> list[list]:\n",
    "    k, m = divmod(len(lst), n_chunks)\n",
    "    return [lst[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n_chunks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b2c3d4-0002-0001-0001-000000000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worker function - each process loads its own model\n",
    "def embed_chunk(args: tuple[int, list[str], str, int]) -> tuple[int, np.ndarray]:\n",
    "    chunk_id, texts, model_name, batch_size = args\n",
    "    \n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    embeddings = model.encode(\n",
    "        texts,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True,\n",
    "        normalize_embeddings=True,\n",
    "    )\n",
    "    return chunk_id, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1b2c3d4-0002-0001-0001-000000000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_batch_parallel(texts: list[str], urls: list[str], symbols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"Embed a batch of texts using multiprocessing and return a dataframe.\"\"\"\n",
    "    text_chunks = chunk_list(texts, N_WORKERS)\n",
    "    args = [(i, tc, MODEL_NAME, BATCH_SIZE) for i, tc in enumerate(text_chunks)]\n",
    "    \n",
    "    with Pool(N_WORKERS) as pool:\n",
    "        results = pool.map(embed_chunk, args)\n",
    "    \n",
    "    # Reassemble in order\n",
    "    results.sort(key=lambda x: x[0])\n",
    "    embeddings = np.vstack([r[1] for r in results])\n",
    "    \n",
    "    # Build dataframe\n",
    "    emb_cols = [f\"emb_{i}\" for i in range(embeddings.shape[1])]\n",
    "    df = pd.DataFrame(embeddings, columns=emb_cols)\n",
    "    df[\"url\"] = urls\n",
    "    df[\"symbol\"] = symbols\n",
    "    return df[[\"url\", \"symbol\"] + emb_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0002-0001-0001-000000000008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9,998 existing embeddings\n",
      "Processing 1,738,719 articles in 1739 batches of ~1,000\n",
      "Using 20 workers\n",
      "------------------------------------------------------------\n",
      "\n",
      "Batch 1/1739: articles 0 - 1,000 (1,000 texts)\n",
      "Progress: 1,000/1,738,719 (0.1%) - checkpoint saved\n",
      "\n",
      "Batch 2/1739: articles 1,000 - 2,000 (1,000 texts)\n",
      "Progress: 2,000/1,738,719 (0.1%) - checkpoint saved\n",
      "\n",
      "Batch 3/1739: articles 2,000 - 3,000 (1,000 texts)\n",
      "Progress: 3,000/1,738,719 (0.2%) - checkpoint saved\n",
      "\n",
      "Batch 4/1739: articles 3,000 - 4,000 (1,000 texts)\n",
      "Progress: 4,000/1,738,719 (0.2%) - checkpoint saved\n",
      "\n",
      "Batch 5/1739: articles 4,000 - 5,000 (1,000 texts)\n",
      "Progress: 5,000/1,738,719 (0.3%) - checkpoint saved\n",
      "\n",
      "Batch 6/1739: articles 5,000 - 6,000 (1,000 texts)\n",
      "Progress: 6,000/1,738,719 (0.3%) - checkpoint saved\n",
      "\n",
      "Batch 7/1739: articles 6,000 - 7,000 (1,000 texts)\n",
      "Progress: 7,000/1,738,719 (0.4%) - checkpoint saved\n",
      "\n",
      "Batch 8/1739: articles 7,000 - 8,000 (1,000 texts)\n",
      "Progress: 8,000/1,738,719 (0.5%) - checkpoint saved\n",
      "\n",
      "Batch 9/1739: articles 8,000 - 9,000 (1,000 texts)\n",
      "Progress: 9,000/1,738,719 (0.5%) - checkpoint saved\n",
      "\n",
      "Batch 10/1739: articles 9,000 - 10,000 (1,000 texts)\n",
      "Progress: 10,000/1,738,719 (0.6%) - checkpoint saved\n",
      "\n",
      "Batch 11/1739: articles 10,000 - 11,000 (1,000 texts)\n",
      "Progress: 11,000/1,738,719 (0.6%) - checkpoint saved\n",
      "\n",
      "Batch 12/1739: articles 11,000 - 12,000 (1,000 texts)\n",
      "Progress: 12,000/1,738,719 (0.7%) - checkpoint saved\n",
      "\n",
      "Batch 13/1739: articles 12,000 - 13,000 (1,000 texts)\n",
      "Progress: 13,000/1,738,719 (0.7%) - checkpoint saved\n",
      "\n",
      "Batch 14/1739: articles 13,000 - 14,000 (1,000 texts)\n",
      "Progress: 14,000/1,738,719 (0.8%) - checkpoint saved\n",
      "\n",
      "Batch 15/1739: articles 14,000 - 15,000 (1,000 texts)\n",
      "Progress: 15,000/1,738,719 (0.9%) - checkpoint saved\n",
      "\n",
      "Batch 16/1739: articles 15,000 - 16,000 (1,000 texts)\n",
      "Progress: 16,000/1,738,719 (0.9%) - checkpoint saved\n",
      "\n",
      "Batch 17/1739: articles 16,000 - 17,000 (1,000 texts)\n",
      "Progress: 17,000/1,738,719 (1.0%) - checkpoint saved\n",
      "\n",
      "Batch 18/1739: articles 17,000 - 18,000 (1,000 texts)\n",
      "Progress: 18,000/1,738,719 (1.0%) - checkpoint saved\n",
      "\n",
      "Batch 19/1739: articles 18,000 - 19,000 (1,000 texts)\n",
      "Progress: 19,000/1,738,719 (1.1%) - checkpoint saved\n",
      "\n",
      "Batch 20/1739: articles 19,000 - 20,000 (1,000 texts)\n",
      "Progress: 20,000/1,738,719 (1.2%) - checkpoint saved\n",
      "\n",
      "Batch 21/1739: articles 20,000 - 21,000 (1,000 texts)\n",
      "Progress: 21,000/1,738,719 (1.2%) - checkpoint saved\n",
      "\n",
      "Batch 22/1739: articles 21,000 - 22,000 (1,000 texts)\n",
      "Progress: 22,000/1,738,719 (1.3%) - checkpoint saved\n",
      "\n",
      "Batch 23/1739: articles 22,000 - 23,000 (1,000 texts)\n",
      "Progress: 23,000/1,738,719 (1.3%) - checkpoint saved\n",
      "\n",
      "Batch 24/1739: articles 23,000 - 24,000 (1,000 texts)\n",
      "Progress: 24,000/1,738,719 (1.4%) - checkpoint saved\n",
      "\n",
      "Batch 25/1739: articles 24,000 - 25,000 (1,000 texts)\n",
      "Progress: 25,000/1,738,719 (1.4%) - checkpoint saved\n",
      "\n",
      "Batch 26/1739: articles 25,000 - 26,000 (1,000 texts)\n",
      "Progress: 26,000/1,738,719 (1.5%) - checkpoint saved\n",
      "\n",
      "Batch 27/1739: articles 26,000 - 27,000 (1,000 texts)\n",
      "Progress: 27,000/1,738,719 (1.6%) - checkpoint saved\n",
      "\n",
      "Batch 28/1739: articles 27,000 - 28,000 (1,000 texts)\n",
      "Progress: 28,000/1,738,719 (1.6%) - checkpoint saved\n",
      "\n",
      "Batch 29/1739: articles 28,000 - 29,000 (1,000 texts)\n",
      "Progress: 29,000/1,738,719 (1.7%) - checkpoint saved\n",
      "\n",
      "Batch 30/1739: articles 29,000 - 30,000 (1,000 texts)\n",
      "Progress: 30,000/1,738,719 (1.7%) - checkpoint saved\n",
      "\n",
      "Batch 31/1739: articles 30,000 - 31,000 (1,000 texts)\n",
      "Progress: 31,000/1,738,719 (1.8%) - checkpoint saved\n",
      "\n",
      "Batch 32/1739: articles 31,000 - 32,000 (1,000 texts)\n",
      "Progress: 32,000/1,738,719 (1.8%) - checkpoint saved\n",
      "\n",
      "Batch 33/1739: articles 32,000 - 33,000 (1,000 texts)\n",
      "Progress: 33,000/1,738,719 (1.9%) - checkpoint saved\n",
      "\n",
      "Batch 34/1739: articles 33,000 - 34,000 (1,000 texts)\n",
      "Progress: 34,000/1,738,719 (2.0%) - checkpoint saved\n",
      "\n",
      "Batch 35/1739: articles 34,000 - 35,000 (1,000 texts)\n",
      "Progress: 35,000/1,738,719 (2.0%) - checkpoint saved\n",
      "\n",
      "Batch 36/1739: articles 35,000 - 36,000 (1,000 texts)\n",
      "Progress: 36,000/1,738,719 (2.1%) - checkpoint saved\n",
      "\n",
      "Batch 37/1739: articles 36,000 - 37,000 (1,000 texts)\n",
      "Progress: 37,000/1,738,719 (2.1%) - checkpoint saved\n",
      "\n",
      "Batch 38/1739: articles 37,000 - 38,000 (1,000 texts)\n",
      "Progress: 38,000/1,738,719 (2.2%) - checkpoint saved\n",
      "\n",
      "Batch 39/1739: articles 38,000 - 39,000 (1,000 texts)\n",
      "Progress: 39,000/1,738,719 (2.2%) - checkpoint saved\n",
      "\n",
      "Batch 40/1739: articles 39,000 - 40,000 (1,000 texts)\n",
      "Progress: 40,000/1,738,719 (2.3%) - checkpoint saved\n",
      "\n",
      "Batch 41/1739: articles 40,000 - 41,000 (1,000 texts)\n",
      "Progress: 41,000/1,738,719 (2.4%) - checkpoint saved\n",
      "\n",
      "Batch 42/1739: articles 41,000 - 42,000 (1,000 texts)\n",
      "Progress: 42,000/1,738,719 (2.4%) - checkpoint saved\n",
      "\n",
      "Batch 43/1739: articles 42,000 - 43,000 (1,000 texts)\n",
      "Progress: 43,000/1,738,719 (2.5%) - checkpoint saved\n",
      "\n",
      "Batch 44/1739: articles 43,000 - 44,000 (1,000 texts)\n",
      "Progress: 44,000/1,738,719 (2.5%) - checkpoint saved\n",
      "\n",
      "Batch 45/1739: articles 44,000 - 45,000 (1,000 texts)\n",
      "Progress: 45,000/1,738,719 (2.6%) - checkpoint saved\n",
      "\n",
      "Batch 46/1739: articles 45,000 - 46,000 (1,000 texts)\n",
      "Progress: 46,000/1,738,719 (2.6%) - checkpoint saved\n",
      "\n",
      "Batch 47/1739: articles 46,000 - 47,000 (1,000 texts)\n",
      "Progress: 47,000/1,738,719 (2.7%) - checkpoint saved\n",
      "\n",
      "Batch 48/1739: articles 47,000 - 48,000 (1,000 texts)\n",
      "Progress: 48,000/1,738,719 (2.8%) - checkpoint saved\n",
      "\n",
      "Batch 49/1739: articles 48,000 - 49,000 (1,000 texts)\n",
      "Progress: 49,000/1,738,719 (2.8%) - checkpoint saved\n",
      "\n",
      "Batch 50/1739: articles 49,000 - 50,000 (1,000 texts)\n",
      "Progress: 50,000/1,738,719 (2.9%) - checkpoint saved\n",
      "\n",
      "Batch 51/1739: articles 50,000 - 51,000 (1,000 texts)\n",
      "Progress: 51,000/1,738,719 (2.9%) - checkpoint saved\n",
      "\n",
      "Batch 52/1739: articles 51,000 - 52,000 (1,000 texts)\n",
      "Progress: 52,000/1,738,719 (3.0%) - checkpoint saved\n",
      "\n",
      "Batch 53/1739: articles 52,000 - 53,000 (1,000 texts)\n",
      "Progress: 53,000/1,738,719 (3.0%) - checkpoint saved\n",
      "\n",
      "Batch 54/1739: articles 53,000 - 54,000 (1,000 texts)\n",
      "Progress: 54,000/1,738,719 (3.1%) - checkpoint saved\n",
      "\n",
      "Batch 55/1739: articles 54,000 - 55,000 (1,000 texts)\n",
      "Progress: 55,000/1,738,719 (3.2%) - checkpoint saved\n",
      "\n",
      "Batch 56/1739: articles 55,000 - 56,000 (1,000 texts)\n",
      "Progress: 56,000/1,738,719 (3.2%) - checkpoint saved\n",
      "\n",
      "Batch 57/1739: articles 56,000 - 57,000 (1,000 texts)\n",
      "Progress: 57,000/1,738,719 (3.3%) - checkpoint saved\n",
      "\n",
      "Batch 58/1739: articles 57,000 - 58,000 (1,000 texts)\n",
      "Progress: 58,000/1,738,719 (3.3%) - checkpoint saved\n",
      "\n",
      "Batch 59/1739: articles 58,000 - 59,000 (1,000 texts)\n",
      "Progress: 59,000/1,738,719 (3.4%) - checkpoint saved\n",
      "\n",
      "Batch 60/1739: articles 59,000 - 60,000 (1,000 texts)\n",
      "Progress: 60,000/1,738,719 (3.5%) - checkpoint saved\n",
      "\n",
      "Batch 61/1739: articles 60,000 - 61,000 (1,000 texts)\n",
      "Progress: 61,000/1,738,719 (3.5%) - checkpoint saved\n",
      "\n",
      "Batch 62/1739: articles 61,000 - 62,000 (1,000 texts)\n",
      "Progress: 62,000/1,738,719 (3.6%) - checkpoint saved\n",
      "\n",
      "Batch 63/1739: articles 62,000 - 63,000 (1,000 texts)\n",
      "Progress: 63,000/1,738,719 (3.6%) - checkpoint saved\n",
      "\n",
      "Batch 64/1739: articles 63,000 - 64,000 (1,000 texts)\n",
      "Progress: 64,000/1,738,719 (3.7%) - checkpoint saved\n",
      "\n",
      "Batch 65/1739: articles 64,000 - 65,000 (1,000 texts)\n",
      "Progress: 65,000/1,738,719 (3.7%) - checkpoint saved\n",
      "\n",
      "Batch 66/1739: articles 65,000 - 66,000 (1,000 texts)\n",
      "Progress: 66,000/1,738,719 (3.8%) - checkpoint saved\n",
      "\n",
      "Batch 67/1739: articles 66,000 - 67,000 (1,000 texts)\n",
      "Progress: 67,000/1,738,719 (3.9%) - checkpoint saved\n",
      "\n",
      "Batch 68/1739: articles 67,000 - 68,000 (1,000 texts)\n",
      "Progress: 68,000/1,738,719 (3.9%) - checkpoint saved\n",
      "\n",
      "Batch 69/1739: articles 68,000 - 69,000 (1,000 texts)\n",
      "Progress: 69,000/1,738,719 (4.0%) - checkpoint saved\n",
      "\n",
      "Batch 70/1739: articles 69,000 - 70,000 (1,000 texts)\n",
      "Progress: 70,000/1,738,719 (4.0%) - checkpoint saved\n",
      "\n",
      "Batch 71/1739: articles 70,000 - 71,000 (1,000 texts)\n"
     ]
    }
   ],
   "source": [
    "if len(texts) == 0:\n",
    "    print(\"Nothing to embed\")\n",
    "else:\n",
    "    n_total = len(texts)\n",
    "    n_batches = (n_total + SAVE_EVERY - 1) // SAVE_EVERY\n",
    "    \n",
    "    # Load existing for appending\n",
    "    try:\n",
    "        existing_df = pd.read_parquet(EMBEDDINGS_PATH)\n",
    "        all_dfs = [existing_df]\n",
    "        print(f\"Loaded {len(existing_df):,} existing embeddings\")\n",
    "    except FileNotFoundError:\n",
    "        all_dfs = []\n",
    "    \n",
    "    print(f\"Processing {n_total:,} articles in {n_batches} batches of ~{SAVE_EVERY:,}\")\n",
    "    print(f\"Using {N_WORKERS} workers\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for batch_idx in range(n_batches):\n",
    "        batch_start = batch_idx * SAVE_EVERY\n",
    "        batch_end = min(batch_start + SAVE_EVERY, n_total)\n",
    "        \n",
    "        batch_texts = texts[batch_start:batch_end]\n",
    "        batch_urls = urls[batch_start:batch_end]\n",
    "        batch_symbols = symbols[batch_start:batch_end]\n",
    "        \n",
    "        print(f\"\\nBatch {batch_idx + 1}/{n_batches}: articles {batch_start:,} - {batch_end:,} ({len(batch_texts):,} texts)\")\n",
    "        \n",
    "        batch_df = embed_batch_parallel(batch_texts, batch_urls, batch_symbols)\n",
    "        all_dfs.append(batch_df)\n",
    "        \n",
    "        # Save checkpoint\n",
    "        combined = pd.concat(all_dfs, ignore_index=True)\n",
    "        combined.to_parquet(EMBEDDINGS_PATH, index=False)\n",
    "        \n",
    "        done = batch_end\n",
    "        pct = done / n_total * 100\n",
    "        print(f\"Progress: {done:,}/{n_total:,} ({pct:.1f}%) - checkpoint saved\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Done! Total embeddings: {len(combined):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0002-0001-0001-000000000009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify final output\n",
    "final_df = pd.read_parquet(EMBEDDINGS_PATH)\n",
    "print(f\"Final embeddings: {len(final_df):,} rows\")\n",
    "print(f\"File size: {final_df.memory_usage(deep=True).sum() / 1e9:.2f} GB\")\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58fa27-1183-4b5d-86a7-e6084f11ca8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
