{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0000-0001-0001-000000000000",
   "metadata": {},
   "source": [
    "# Fundamentals Data\n",
    "\n",
    "Download quarterly fundamentals from FMP:\n",
    "- Key metrics (P/E, EV/EBITDA, etc.)\n",
    "- Financial ratios (ROE, margins, etc.)\n",
    "- Financial growth (YoY revenue/earnings growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b2c3d4-0001-0001-0001-000000000001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "os.environ[\"FMP_API_KEY\"] = \"67jXuKOp0KmWB6FyH9k86zlxnTJSAql7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b2c3d4-0001-0001-0001-000000000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "FMP_BASE_URL = \"https://financialmodelingprep.com/stable\"\n",
    "SAVE_EVERY = 500\n",
    "MAX_CALLS_PER_MINUTE = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b2c3d4-0001-0001-0001-000000000003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6,060 symbols\n"
     ]
    }
   ],
   "source": [
    "universe = pd.read_parquet(\"data/universe.pqt\")\n",
    "symbols = universe[\"symbol\"].dropna().astype(str).unique().tolist()\n",
    "print(f\"Loaded {len(symbols):,} symbols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1b2c3d4-0001-0001-0001-000000000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RateLimiter:\n",
    "    def __init__(self, max_per_minute: int = 240):\n",
    "        self.max_per_minute = max_per_minute\n",
    "        self._last_call = 0.0\n",
    "    \n",
    "    @property\n",
    "    def min_interval(self) -> float:\n",
    "        return 60.0 / self.max_per_minute\n",
    "    \n",
    "    def wait(self) -> None:\n",
    "        now = time.time()\n",
    "        elapsed = now - self._last_call\n",
    "        if elapsed < self.min_interval:\n",
    "            time.sleep(self.min_interval - elapsed)\n",
    "        self._last_call = time.time()\n",
    "\n",
    "\n",
    "def request_json(\n",
    "    session: requests.Session,\n",
    "    path: str,\n",
    "    params: dict,\n",
    "    max_retries: int = 8,\n",
    ") -> list | dict:\n",
    "    url = f\"{FMP_BASE_URL}{path}\"\n",
    "    for attempt in range(max_retries):\n",
    "        resp = session.get(url, params=params, timeout=30)\n",
    "        if resp.status_code == 200:\n",
    "            return resp.json()\n",
    "        if resp.status_code in (429, 500, 502, 503, 504):\n",
    "            sleep_time = min(60, (2**attempt) + random.random())\n",
    "            time.sleep(sleep_time)\n",
    "            continue\n",
    "        resp.raise_for_status()\n",
    "    raise RuntimeError(f\"Failed after {max_retries} retries: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b2c3d4-0001-0001-0001-000000000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_fundamentals(\n",
    "    session: requests.Session,\n",
    "    symbol: str,\n",
    "    api_key: str,\n",
    "    rate_limiter: RateLimiter,\n",
    ") -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"Fetch key metrics, ratios, and growth for a symbol.\"\"\"\n",
    "    endpoints = {\n",
    "        \"key_metrics\": \"/key-metrics\",\n",
    "        \"ratios\": \"/ratios\",\n",
    "        \"growth\": \"/financial-growth\",\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for name, path in endpoints.items():\n",
    "        rate_limiter.wait()\n",
    "        params = {\n",
    "            \"symbol\": symbol,\n",
    "            \"period\": \"quarter\",\n",
    "            \"apikey\": api_key,\n",
    "        }\n",
    "        data = request_json(session, path, params)\n",
    "        if data:\n",
    "            df = pd.DataFrame(data)\n",
    "            df[\"symbol\"] = symbol\n",
    "            results[name] = df\n",
    "        else:\n",
    "            results[name] = pd.DataFrame()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b2c3d4-0001-0001-0001-000000000006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing progress found\n",
      "6,060 symbols to fetch\n"
     ]
    }
   ],
   "source": [
    "# Check for existing progress\n",
    "DATA_DIR = Path(\"data\")\n",
    "PROGRESS_PATH = DATA_DIR / \"fundamentals_progress.txt\"\n",
    "\n",
    "METRICS_PATH = DATA_DIR / \"key_metrics.pqt\"\n",
    "RATIOS_PATH = DATA_DIR / \"ratios.pqt\"\n",
    "GROWTH_PATH = DATA_DIR / \"growth.pqt\"\n",
    "\n",
    "if PROGRESS_PATH.exists():\n",
    "    done_symbols = set(PROGRESS_PATH.read_text().strip().split(\"\\n\"))\n",
    "    done_symbols.discard(\"\")\n",
    "    print(f\"Found {len(done_symbols):,} completed symbols\")\n",
    "else:\n",
    "    done_symbols = set()\n",
    "    print(\"No existing progress found\")\n",
    "\n",
    "# Load existing data if resuming\n",
    "def load_existing(path: Path) -> pd.DataFrame | None:\n",
    "    if path.exists():\n",
    "        return pd.read_parquet(path)\n",
    "    return None\n",
    "\n",
    "existing_metrics = load_existing(METRICS_PATH)\n",
    "existing_ratios = load_existing(RATIOS_PATH)\n",
    "existing_growth = load_existing(GROWTH_PATH)\n",
    "\n",
    "symbols_to_fetch = [s for s in symbols if s not in done_symbols]\n",
    "print(f\"{len(symbols_to_fetch):,} symbols to fetch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0001-0001-0001-000000000007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching fundamentals for 6,060 symbols (3 API calls each)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bb528a000c4c7a8aaccf1cf2943d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Symbols:   0%|          | 0/6060 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_603161/1086971692.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_metrics = pd.concat(all_metrics, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "if len(symbols_to_fetch) == 0:\n",
    "    print(\"Nothing to fetch\")\n",
    "else:\n",
    "    api_key = os.environ[\"FMP_API_KEY\"]\n",
    "    session = requests.Session()\n",
    "    rate_limiter = RateLimiter(max_per_minute=MAX_CALLS_PER_MINUTE)\n",
    "    \n",
    "    # Initialize accumulators\n",
    "    all_metrics = [existing_metrics] if existing_metrics is not None else []\n",
    "    all_ratios = [existing_ratios] if existing_ratios is not None else []\n",
    "    all_growth = [existing_growth] if existing_growth is not None else []\n",
    "    \n",
    "    batch_metrics = []\n",
    "    batch_ratios = []\n",
    "    batch_growth = []\n",
    "    newly_done = []\n",
    "    \n",
    "    n_total = len(symbols_to_fetch)\n",
    "    n_errors = 0\n",
    "    \n",
    "    print(f\"Fetching fundamentals for {n_total:,} symbols (3 API calls each)\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, symbol in enumerate(tqdm(symbols_to_fetch, desc=\"Symbols\")):\n",
    "        try:\n",
    "            results = fetch_fundamentals(session, symbol, api_key, rate_limiter)\n",
    "            \n",
    "            if not results[\"key_metrics\"].empty:\n",
    "                batch_metrics.append(results[\"key_metrics\"])\n",
    "            if not results[\"ratios\"].empty:\n",
    "                batch_ratios.append(results[\"ratios\"])\n",
    "            if not results[\"growth\"].empty:\n",
    "                batch_growth.append(results[\"growth\"])\n",
    "            \n",
    "            newly_done.append(symbol)\n",
    "        except Exception as e:\n",
    "            n_errors += 1\n",
    "            tqdm.write(f\"Error fetching {symbol}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if (i + 1) % SAVE_EVERY == 0 or (i + 1) == n_total:\n",
    "            # Combine and save metrics\n",
    "            if batch_metrics:\n",
    "                all_metrics.extend(batch_metrics)\n",
    "                combined_metrics = pd.concat(all_metrics, ignore_index=True)\n",
    "                combined_metrics.to_parquet(METRICS_PATH, index=False)\n",
    "                batch_metrics = []\n",
    "                all_metrics = [combined_metrics]\n",
    "            \n",
    "            # Combine and save ratios\n",
    "            if batch_ratios:\n",
    "                all_ratios.extend(batch_ratios)\n",
    "                combined_ratios = pd.concat(all_ratios, ignore_index=True)\n",
    "                combined_ratios.to_parquet(RATIOS_PATH, index=False)\n",
    "                batch_ratios = []\n",
    "                all_ratios = [combined_ratios]\n",
    "            \n",
    "            # Combine and save growth\n",
    "            if batch_growth:\n",
    "                all_growth.extend(batch_growth)\n",
    "                combined_growth = pd.concat(all_growth, ignore_index=True)\n",
    "                combined_growth.to_parquet(GROWTH_PATH, index=False)\n",
    "                batch_growth = []\n",
    "                all_growth = [combined_growth]\n",
    "            \n",
    "            # Update progress\n",
    "            done_symbols.update(newly_done)\n",
    "            PROGRESS_PATH.write_text(\"\\n\".join(sorted(done_symbols)))\n",
    "            newly_done = []\n",
    "            \n",
    "            pct = (i + 1) / n_total * 100\n",
    "            tqdm.write(f\"Checkpoint: {i + 1:,}/{n_total:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Done! Errors: {n_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0001-0001-0001-000000000008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify outputs\n",
    "metrics = pd.read_parquet(METRICS_PATH)\n",
    "ratios = pd.read_parquet(RATIOS_PATH)\n",
    "growth = pd.read_parquet(GROWTH_PATH)\n",
    "\n",
    "print(f\"Key metrics: {len(metrics):,} rows, {metrics['symbol'].nunique():,} symbols\")\n",
    "print(f\"Ratios: {len(ratios):,} rows, {ratios['symbol'].nunique():,} symbols\")\n",
    "print(f\"Growth: {len(growth):,} rows, {growth['symbol'].nunique():,} symbols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0001-0001-0001-000000000009",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Key metrics columns:\")\n",
    "print(list(metrics.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0001-0001-0001-000000000010",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ratios columns:\")\n",
    "print(list(ratios.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0001-0001-0001-000000000011",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Growth columns:\")\n",
    "print(list(growth.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-0001-0001-0001-000000000012",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1551f0-9d4d-4393-94a4-9da90b92568e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
