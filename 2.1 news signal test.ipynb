{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0000-0001-0001-000000000000",
   "metadata": {},
   "source": [
    "# News Embedding Signal Test\n",
    "\n",
    "Test whether news embeddings contain non-linear predictive signal for returns.\n",
    "\n",
    "Approach: Train a small MLP on embeddings only to predict above/below median return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b2c3d4-0001-0001-0001-000000000001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b2c3d4-0001-0001-0001-000000000002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 2,092,929\n",
      "Rows with news: 194,220 (9.3%)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"data/ml_dataset.pqt\")\n",
    "df[\"feature_date\"] = pd.to_datetime(df[\"feature_date\"])\n",
    "\n",
    "# Only rows with news\n",
    "emb_cols = [c for c in df.columns if c.startswith(\"emb_\")]\n",
    "has_news = (df[emb_cols].abs().sum(axis=1) > 0)\n",
    "news_df = df[has_news].copy()\n",
    "\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"Rows with news: {len(news_df):,} ({len(news_df)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b2c3d4-0001-0001-0001-000000000003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 125,880 rows, 830 days\n",
      "Val: 68,340 rows, 356 days\n",
      "\n",
      "Train period: 2021-01-13 to 2024-05-01\n",
      "Val period: 2024-05-02 to 2025-12-18\n"
     ]
    }
   ],
   "source": [
    "# Time-based split (70% train, 30% val)\n",
    "dates = sorted(news_df[\"feature_date\"].unique())\n",
    "split_date = dates[int(len(dates) * 0.7)]\n",
    "\n",
    "train_df = news_df[news_df[\"feature_date\"] < split_date].copy()\n",
    "val_df = news_df[news_df[\"feature_date\"] >= split_date].copy()\n",
    "\n",
    "print(f\"Train: {len(train_df):,} rows, {train_df['feature_date'].nunique()} days\")\n",
    "print(f\"Val: {len(val_df):,} rows, {val_df['feature_date'].nunique()} days\")\n",
    "print(f\"\\nTrain period: {train_df['feature_date'].min().date()} to {train_df['feature_date'].max().date()}\")\n",
    "print(f\"Val period: {val_df['feature_date'].min().date()} to {val_df['feature_date'].max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1b2c3d4-0001-0001-0001-000000000004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label balance (train): 0.498\n",
      "Label balance (val): 0.499\n"
     ]
    }
   ],
   "source": [
    "# Binary classification: above/below median return that day (cross-sectional)\n",
    "train_df[\"label\"] = (train_df.groupby(\"feature_date\")[\"target_return\"]\n",
    "                     .transform(lambda x: (x > x.median()).astype(int)))\n",
    "val_df[\"label\"] = (val_df.groupby(\"feature_date\")[\"target_return\"]\n",
    "                   .transform(lambda x: (x > x.median()).astype(int)))\n",
    "\n",
    "print(f\"Label balance (train): {train_df['label'].mean():.3f}\")\n",
    "print(f\"Label balance (val): {val_df['label'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b2c3d4-0001-0001-0001-000000000005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([125880, 768])\n",
      "X_val: torch.Size([68340, 768])\n"
     ]
    }
   ],
   "source": [
    "# Prepare tensors\n",
    "X_train = torch.tensor(train_df[emb_cols].values, dtype=torch.float32)\n",
    "X_val = torch.tensor(val_df[emb_cols].values, dtype=torch.float32)\n",
    "y_train = torch.tensor(train_df[\"label\"].values, dtype=torch.float32)\n",
    "y_val = torch.tensor(val_df[\"label\"].values, dtype=torch.float32)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b2c3d4-0001-0001-0001-000000000006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 102,593\n"
     ]
    }
   ],
   "source": [
    "class NewsClassifier(nn.Module):\n",
    "    \"\"\"Simple MLP to test if embeddings have predictive signal.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=768, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "model = NewsClassifier(input_dim=len(emb_cols)).to(device)\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1b2c3d4-0001-0001-0001-000000000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(X_train, y_train), \n",
    "    batch_size=512, \n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    TensorDataset(X_val, y_val), \n",
    "    batch_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1b2c3d4-0001-0001-0001-000000000008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: train_acc=0.5031, val_acc=0.5012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: train_acc=0.5024, val_acc=0.5013\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: train_acc=0.5015, val_acc=0.5013\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: train_acc=0.5011, val_acc=0.5055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: train_acc=0.5011, val_acc=0.5047\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: train_acc=0.5043, val_acc=0.5020\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: train_acc=0.5014, val_acc=0.5013\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: train_acc=0.5037, val_acc=0.5019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: train_acc=0.5046, val_acc=0.5012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: train_acc=0.5046, val_acc=0.5047\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: train_acc=0.5051, val_acc=0.5010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: train_acc=0.5064, val_acc=0.5025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: train_acc=0.5070, val_acc=0.5065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: train_acc=0.5067, val_acc=0.5060\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: train_acc=0.5056, val_acc=0.5067\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: train_acc=0.5070, val_acc=0.5058\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: train_acc=0.5090, val_acc=0.5052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: train_acc=0.5088, val_acc=0.5046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: train_acc=0.5087, val_acc=0.5012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20:   0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: train_acc=0.5094, val_acc=0.5050\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "n_epochs = 20\n",
    "history = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss, train_correct, train_total = 0, 0, 0\n",
    "    for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch+1}\", leave=False):\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * len(yb)\n",
    "        train_correct += ((pred > 0) == (yb > 0.5)).sum().item()\n",
    "        train_total += len(yb)\n",
    "    \n",
    "    # Validate\n",
    "    model.eval()\n",
    "    val_correct, val_total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            pred = model(xb)\n",
    "            val_correct += ((pred > 0) == (yb > 0.5)).sum().item()\n",
    "            val_total += len(yb)\n",
    "    \n",
    "    train_acc = train_correct / train_total\n",
    "    val_acc = val_correct / val_total\n",
    "    \n",
    "    history.append({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss / train_total,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_acc\": val_acc,\n",
    "    })\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}: train_acc={train_acc:.4f}, val_acc={val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1b2c3d4-0001-0001-0001-000000000009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RESULTS\n",
      "==================================================\n",
      "\n",
      "Baseline (random): 50.0%\n",
      "Best val accuracy: 50.67%\n",
      "Final val accuracy: 50.50%\n",
      "\n",
      "Signal above random: +0.67%\n",
      "\n",
      "=> Weak signal, may not be reliable\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nBaseline (random): 50.0%\")\n",
    "print(f\"Best val accuracy: {max(h['val_acc'] for h in history)*100:.2f}%\")\n",
    "print(f\"Final val accuracy: {history[-1]['val_acc']*100:.2f}%\")\n",
    "\n",
    "delta = (max(h['val_acc'] for h in history) - 0.5) * 100\n",
    "print(f\"\\nSignal above random: {delta:+.2f}%\")\n",
    "\n",
    "if delta > 1:\n",
    "    print(\"\\n=> News embeddings have SOME predictive signal\")\n",
    "elif delta > 0.5:\n",
    "    print(\"\\n=> Weak signal, may not be reliable\")\n",
    "else:\n",
    "    print(\"\\n=> No detectable signal in news embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-0001-0001-0001-000000000010",
   "metadata": {},
   "source": [
    "## Pairwise Test\n",
    "\n",
    "Alternative: test if embeddings can predict which of two stocks will outperform (same as main model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1b2c3d4-0001-0001-0001-000000000011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating validation pairs...\n",
      "Generated 178,000 pairs\n"
     ]
    }
   ],
   "source": [
    "# Generate pairs from validation set (fresh, not used in training)\n",
    "def generate_pairs(df, emb_cols, n_pairs_per_day=500):\n",
    "    \"\"\"Generate pairs for pairwise ranking test.\"\"\"\n",
    "    pairs = []\n",
    "    \n",
    "    for date, group in df.groupby(\"feature_date\"):\n",
    "        if len(group) < 10:\n",
    "            continue\n",
    "        \n",
    "        # Sample random pairs\n",
    "        n = min(n_pairs_per_day, len(group) * (len(group) - 1) // 2)\n",
    "        indices = group.index.tolist()\n",
    "        \n",
    "        for _ in range(n):\n",
    "            i, j = np.random.choice(indices, 2, replace=False)\n",
    "            ret_i = df.loc[i, \"target_return\"]\n",
    "            ret_j = df.loc[j, \"target_return\"]\n",
    "            emb_i = df.loc[i, emb_cols].values.astype(np.float32)\n",
    "            emb_j = df.loc[j, emb_cols].values.astype(np.float32)\n",
    "            \n",
    "            # Label: 1 if i > j, else 0\n",
    "            label = 1.0 if ret_i > ret_j else 0.0\n",
    "            \n",
    "            pairs.append({\n",
    "                \"emb_i\": emb_i,\n",
    "                \"emb_j\": emb_j,\n",
    "                \"label\": label,\n",
    "            })\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "print(\"Generating validation pairs...\")\n",
    "val_pairs = generate_pairs(val_df, emb_cols, n_pairs_per_day=500)\n",
    "print(f\"Generated {len(val_pairs):,} pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1b2c3d4-0001-0001-0001-000000000012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60de5c00ba014982b70527dffdfd1c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating pairs:   0%|          | 0/178000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pairwise ranking accuracy: 50.78%\n",
      "Baseline (random): 50.0%\n",
      "Signal above random: +0.78%\n"
     ]
    }
   ],
   "source": [
    "# Test the trained model on pairs\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for pair in tqdm(val_pairs, desc=\"Evaluating pairs\"):\n",
    "        emb_i = torch.tensor(pair[\"emb_i\"], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        emb_j = torch.tensor(pair[\"emb_j\"], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        \n",
    "        score_i = model(emb_i).item()\n",
    "        score_j = model(emb_j).item()\n",
    "        \n",
    "        pred = 1 if score_i > score_j else 0\n",
    "        label = int(pair[\"label\"])\n",
    "        \n",
    "        if pred == label:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "pairwise_acc = correct / total\n",
    "print(f\"\\nPairwise ranking accuracy: {pairwise_acc*100:.2f}%\")\n",
    "print(f\"Baseline (random): 50.0%\")\n",
    "print(f\"Signal above random: {(pairwise_acc - 0.5)*100:+.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gsy4bcau404",
   "metadata": {},
   "source": [
    "## Top/Bottom-K Selection Test\n",
    "\n",
    "What matters for trading: Can the model identify stocks that end up in the top or bottom K?\n",
    "\n",
    "Test: Of stocks the model ranks in its top-K, what fraction are actually in the true top-K?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "mhesi1toub",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scored 68,340 rows\n"
     ]
    }
   ],
   "source": [
    "# Score all validation rows\n",
    "model.eval()\n",
    "val_df = val_df.copy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    scores = model(X_val.to(device)).cpu().numpy()\n",
    "val_df[\"score\"] = scores\n",
    "\n",
    "print(f\"Scored {len(val_df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "p5mhkteg1lb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 1,068 day-k combinations\n"
     ]
    }
   ],
   "source": [
    "def evaluate_topk_selection(df, k_values=[5, 10, 20]):\n",
    "    \"\"\"\n",
    "    For each day, check if model's top-K picks overlap with actual top-K performers.\n",
    "    Also check bottom-K (for shorting).\n",
    "    \n",
    "    Returns precision: what fraction of model's picks are in the true top/bottom K.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for date, group in df.groupby(\"feature_date\"):\n",
    "        n = len(group)\n",
    "        if n < 40:  # Need enough stocks for meaningful top/bottom K\n",
    "            continue\n",
    "        \n",
    "        for k in k_values:\n",
    "            if k > n // 4:\n",
    "                continue\n",
    "                \n",
    "            # Model's top-K and bottom-K by score\n",
    "            model_top_k = set(group.nlargest(k, \"score\").index)\n",
    "            model_bottom_k = set(group.nsmallest(k, \"score\").index)\n",
    "            \n",
    "            # Actual top-K and bottom-K by return\n",
    "            actual_top_k = set(group.nlargest(k, \"target_return\").index)\n",
    "            actual_bottom_k = set(group.nsmallest(k, \"target_return\").index)\n",
    "            \n",
    "            # Precision: overlap / k\n",
    "            top_precision = len(model_top_k & actual_top_k) / k\n",
    "            bottom_precision = len(model_bottom_k & actual_bottom_k) / k\n",
    "            \n",
    "            # Random baseline: k/n (probability of randomly picking a true top-K stock)\n",
    "            random_baseline = k / n\n",
    "            \n",
    "            results.append({\n",
    "                \"date\": date,\n",
    "                \"k\": k,\n",
    "                \"n_stocks\": n,\n",
    "                \"top_precision\": top_precision,\n",
    "                \"bottom_precision\": bottom_precision,\n",
    "                \"random_baseline\": random_baseline,\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "results_df = evaluate_topk_selection(val_df, k_values=[5, 10, 20])\n",
    "print(f\"Evaluated {len(results_df):,} day-k combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "st1agj4tla",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TOP-K SELECTION ACCURACY (for going long)\n",
      "======================================================================\n",
      "K     Precision    Random       Lift         t-stat    \n",
      "----------------------------------------------------------------------\n",
      "5      2.36%       2.69%       0.88x      -0.94\n",
      "10     4.44%       5.38%       0.83x      -2.69\n",
      "20     9.28%      10.76%       0.86x      -4.31\n",
      "\n",
      "\n",
      "======================================================================\n",
      "BOTTOM-K SELECTION ACCURACY (for shorting)\n",
      "======================================================================\n",
      "K     Precision    Random       Lift         t-stat    \n",
      "----------------------------------------------------------------------\n",
      "5      5.17%       2.69%       1.92x      +4.75\n",
      "10     8.68%       5.38%       1.61x      +6.66\n",
      "20    15.63%      10.76%       1.45x      +10.54\n"
     ]
    }
   ],
   "source": [
    "# Summary by K\n",
    "print(\"=\" * 70)\n",
    "print(\"TOP-K SELECTION ACCURACY (for going long)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'K':<5} {'Precision':<12} {'Random':<12} {'Lift':<12} {'t-stat':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for k in [5, 10, 20]:\n",
    "    subset = results_df[results_df[\"k\"] == k]\n",
    "    if len(subset) == 0:\n",
    "        continue\n",
    "    precision = subset[\"top_precision\"].mean()\n",
    "    baseline = subset[\"random_baseline\"].mean()\n",
    "    lift = precision / baseline\n",
    "    \n",
    "    # t-test vs baseline\n",
    "    from scipy.stats import ttest_1samp\n",
    "    t_stat, p_val = ttest_1samp(subset[\"top_precision\"], baseline)\n",
    "    \n",
    "    print(f\"{k:<5} {precision*100:>5.2f}%      {baseline*100:>5.2f}%      {lift:>5.2f}x      {t_stat:>+5.2f}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"=\" * 70)\n",
    "print(\"BOTTOM-K SELECTION ACCURACY (for shorting)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'K':<5} {'Precision':<12} {'Random':<12} {'Lift':<12} {'t-stat':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for k in [5, 10, 20]:\n",
    "    subset = results_df[results_df[\"k\"] == k]\n",
    "    if len(subset) == 0:\n",
    "        continue\n",
    "    precision = subset[\"bottom_precision\"].mean()\n",
    "    baseline = subset[\"random_baseline\"].mean()\n",
    "    lift = precision / baseline\n",
    "    \n",
    "    t_stat, p_val = ttest_1samp(subset[\"bottom_precision\"], baseline)\n",
    "    \n",
    "    print(f\"{k:<5} {precision*100:>5.2f}%      {baseline*100:>5.2f}%      {lift:>5.2f}x      {t_stat:>+5.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ym5zkkyorza",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================================================================\n",
      "AVERAGE RETURN OF MODEL PICKS\n",
      "======================================================================\n",
      "\n",
      "K=5:\n",
      "  Model's Top-5 avg return:    +0.106% (market: -0.070%)\n",
      "  Model's Bottom-5 avg return: -0.263%\n",
      "  Short P&L (if shorting bottom): +0.263%\n",
      "  Long-Short spread:              +0.369%\n",
      "\n",
      "K=10:\n",
      "  Model's Top-10 avg return:    -0.011% (market: -0.070%)\n",
      "  Model's Bottom-10 avg return: -0.224%\n",
      "  Short P&L (if shorting bottom): +0.224%\n",
      "  Long-Short spread:              +0.214%\n",
      "\n",
      "K=20:\n",
      "  Model's Top-20 avg return:    -0.026% (market: -0.070%)\n",
      "  Model's Bottom-20 avg return: -0.184%\n",
      "  Short P&L (if shorting bottom): +0.184%\n",
      "  Long-Short spread:              +0.158%\n"
     ]
    }
   ],
   "source": [
    "# More practical test: What's the average return of model's picks vs random?\n",
    "print(\"\\n\")\n",
    "print(\"=\" * 70)\n",
    "print(\"AVERAGE RETURN OF MODEL PICKS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for k in [5, 10, 20]:\n",
    "    top_returns = []\n",
    "    bottom_returns = []\n",
    "    market_returns = []\n",
    "    \n",
    "    for date, group in val_df.groupby(\"feature_date\"):\n",
    "        if len(group) < 40:\n",
    "            continue\n",
    "        \n",
    "        # Model picks\n",
    "        model_top = group.nlargest(k, \"score\")\n",
    "        model_bottom = group.nsmallest(k, \"score\")\n",
    "        \n",
    "        top_returns.append(model_top[\"target_return\"].mean())\n",
    "        bottom_returns.append(model_bottom[\"target_return\"].mean())\n",
    "        market_returns.append(group[\"target_return\"].mean())\n",
    "    \n",
    "    top_ret = np.mean(top_returns) * 100\n",
    "    bottom_ret = np.mean(bottom_returns) * 100\n",
    "    mkt_ret = np.mean(market_returns) * 100\n",
    "    \n",
    "    # Short P&L is negative of bottom returns\n",
    "    short_pnl = -bottom_ret\n",
    "    \n",
    "    print(f\"\\nK={k}:\")\n",
    "    print(f\"  Model's Top-{k} avg return:    {top_ret:+.3f}% (market: {mkt_ret:+.3f}%)\")\n",
    "    print(f\"  Model's Bottom-{k} avg return: {bottom_ret:+.3f}%\")\n",
    "    print(f\"  Short P&L (if shorting bottom): {short_pnl:+.3f}%\")\n",
    "    print(f\"  Long-Short spread:              {top_ret - bottom_ret:+.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b891f5-85bf-4bed-8dd4-af0753ddbf3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
