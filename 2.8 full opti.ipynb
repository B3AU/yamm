{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.8 Robust Tail Optimization\n",
    "\n",
    "Hyperparameter optimization using tail-aware metrics that are robust to outliers.\n",
    "\n",
    "**Selection Metrics:**\n",
    "1. **Winsorized Sharpe** - Clip returns at 5th/95th percentile before computing Sharpe\n",
    "2. **CVaR (5%)** - Average return in worst 5% of days (Expected Shortfall)\n",
    "3. **Sortino Ratio** - Mean / downside std (only penalizes negative volatility)\n",
    "\n",
    "**Why these metrics?**\n",
    "- IC Sharpe ignores actual return magnitudes\n",
    "- Raw Short Sharpe is dominated by single outliers (30% SL cliff)\n",
    "- These metrics balance tail-awareness with robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    n_fundamental_features: int = 19\n",
    "    n_price_features: int = 9\n",
    "    n_embedding_dim: int = 768\n",
    "    fund_hidden: int = 64\n",
    "    price_hidden: int = 32\n",
    "    news_hidden: int = 128\n",
    "    fundamental_latent: int = 32\n",
    "    price_latent: int = 16\n",
    "    news_latent: int = 32\n",
    "    fundamental_dropout: float = 0.6\n",
    "    price_dropout: float = 0.3\n",
    "    news_dropout: float = 0.1\n",
    "    news_alpha: float = 0.8\n",
    "    batch_size: int = 512\n",
    "    learning_rate: float = 1e-3\n",
    "    weight_decay: float = 1e-3\n",
    "    label_smoothing: float = 0.1\n",
    "    n_epochs: int = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 2,092,929 rows\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"data/ml_dataset.pqt\")\n",
    "df[\"feature_date\"] = pd.to_datetime(df[\"feature_date\"])\n",
    "df[\"simple_return\"] = np.exp(df[\"target_return\"]) - 1\n",
    "\n",
    "# Clip for training only\n",
    "CLIP_LIMIT = 1.0\n",
    "df[\"simple_return_clipped\"] = df[\"simple_return\"].clip(-CLIP_LIMIT, CLIP_LIMIT)\n",
    "\n",
    "print(f\"Dataset: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price: 9, Fund: 19, Emb: 768\n"
     ]
    }
   ],
   "source": [
    "price_feat_cols = [\n",
    "    \"overnight_gap_z\", \"intraday_ret_z\",\n",
    "    \"ret_1d_z\", \"ret_2d_z\", \"ret_3d_z\", \"ret_5d_z\",\n",
    "    \"vol_5d_z\", \"dist_from_high_5d_z\", \"dist_from_low_5d_z\"\n",
    "]\n",
    "fund_feat_cols = [c for c in df.columns if c.endswith(\"_z\") and c not in price_feat_cols and c != \"news_count_z\"]\n",
    "emb_cols = [c for c in df.columns if c.startswith(\"emb_\")]\n",
    "\n",
    "print(f\"Price: {len(price_feat_cols)}, Fund: {len(fund_feat_cols)}, Emb: {len(emb_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1,418,494, Val: 58,882, Test: 128,502\n"
     ]
    }
   ],
   "source": [
    "# Time split\n",
    "dates = sorted(df[\"feature_date\"].unique())\n",
    "n_dates = len(dates)\n",
    "train_end = int(n_dates * 0.7)\n",
    "val_end = int(n_dates * 0.8)\n",
    "\n",
    "train_dates = set(dates[:train_end])\n",
    "val_dates = set(dates[train_end:val_end])\n",
    "test_dates = set(dates[val_end:])\n",
    "\n",
    "train_df = df[df[\"feature_date\"].isin(train_dates)].copy()\n",
    "val_df = df[df[\"feature_date\"].isin(val_dates)].copy()\n",
    "test_df = df[df[\"feature_date\"].isin(test_dates)].copy()\n",
    "\n",
    "def filter_news_only(df_in):\n",
    "    has_news = (df_in[emb_cols].abs().sum(axis=1) > 0)\n",
    "    return df_in[has_news].copy()\n",
    "\n",
    "val_df_news = filter_news_only(val_df)\n",
    "test_df_news = filter_news_only(test_df)\n",
    "\n",
    "print(f\"Train: {len(train_df):,}, Val: {len(val_df_news):,}, Test: {len(test_df_news):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinglePairDataset(Dataset):\n",
    "    def __init__(self, df, price_cols, fund_cols, emb_cols, verbose=True):\n",
    "        has_news = (df[emb_cols].abs().sum(axis=1) > 0)\n",
    "        df_news = df[has_news].copy().reset_index(drop=True)\n",
    "        if verbose:\n",
    "            print(f\"Filtered to news-only: {len(df_news):,} rows\")\n",
    "\n",
    "        self.df = df_news\n",
    "        self.price_cols = price_cols\n",
    "        self.fund_cols = fund_cols\n",
    "        self.emb_cols = emb_cols\n",
    "\n",
    "        self.date_groups = {}\n",
    "        for date, group in self.df.groupby(\"feature_date\"):\n",
    "            indices = group.index.tolist()\n",
    "            if len(indices) >= 2:\n",
    "                self.date_groups[date] = indices\n",
    "        self.dates = list(self.date_groups.keys())\n",
    "\n",
    "        self.price_arr = self.df[price_cols].values.astype(np.float32)\n",
    "        self.fund_arr = self.df[fund_cols].values.astype(np.float32)\n",
    "        self.emb_arr = self.df[emb_cols].values.astype(np.float32)\n",
    "        self.target_arr = self.df[\"simple_return_clipped\"].values.astype(np.float32)\n",
    "\n",
    "        self.pairs = []\n",
    "        self._generate_pairs(verbose=verbose)\n",
    "\n",
    "    def _generate_pairs(self, verbose=False):\n",
    "        pairs = []\n",
    "        for date in self.dates:\n",
    "            indices = list(self.date_groups[date])\n",
    "            np.random.shuffle(indices)\n",
    "            for i in range(0, len(indices) - 1, 2):\n",
    "                pairs.append((indices[i], indices[i + 1]))\n",
    "        self.pairs = pairs\n",
    "        if verbose:\n",
    "            print(f\"Generated {len(self.pairs):,} pairs\")\n",
    "\n",
    "    def resample_pairs(self):\n",
    "        self._generate_pairs()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i, j = self.pairs[idx]\n",
    "        price_i, price_j = self.price_arr[i], self.price_arr[j]\n",
    "        fund_i, fund_j = self.fund_arr[i], self.fund_arr[j]\n",
    "        emb_i, emb_j = self.emb_arr[i], self.emb_arr[j]\n",
    "        label = 1.0 if self.target_arr[i] > self.target_arr[j] else 0.0\n",
    "\n",
    "        if np.random.random() < 0.5:\n",
    "            price_i, price_j = price_j, price_i\n",
    "            fund_i, fund_j = fund_j, fund_i\n",
    "            emb_i, emb_j = emb_j, emb_i\n",
    "            label = 1.0 - label\n",
    "\n",
    "        return {\n",
    "            \"price_i\": torch.tensor(price_i), \"price_j\": torch.tensor(price_j),\n",
    "            \"fund_i\": torch.tensor(fund_i), \"fund_j\": torch.tensor(fund_j),\n",
    "            \"emb_i\": torch.tensor(emb_i), \"emb_j\": torch.tensor(emb_j),\n",
    "            \"label\": torch.tensor(label),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBranchRanker(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.fund_encoder = nn.Sequential(\n",
    "            nn.Linear(config.n_fundamental_features, config.fund_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.fundamental_dropout),\n",
    "            nn.Linear(config.fund_hidden, config.fundamental_latent),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.price_encoder = nn.Sequential(\n",
    "            nn.Linear(config.n_price_features, config.price_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.price_dropout),\n",
    "            nn.Linear(config.price_hidden, config.price_latent),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.news_encoder = nn.Sequential(\n",
    "            nn.Linear(config.n_embedding_dim, config.news_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.news_dropout),\n",
    "            nn.Linear(config.news_hidden, config.news_latent),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        fused_dim = config.fundamental_latent + config.price_latent + config.news_latent\n",
    "        self.output_head = nn.Sequential(\n",
    "            nn.Linear(fused_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, price, fund, emb):\n",
    "        h_f = self.fund_encoder(fund)\n",
    "        h_p = self.price_encoder(price)\n",
    "        h_n = self.news_encoder(emb)\n",
    "        h_n_scaled = self.config.news_alpha * h_n\n",
    "        h = torch.cat([h_f, h_p, h_n_scaled], dim=-1)\n",
    "        return self.output_head(h).squeeze(-1)\n",
    "    \n",
    "    def forward_pair(self, price_i, fund_i, emb_i, price_j, fund_j, emb_j):\n",
    "        score_i = self.forward(price_i, fund_i, emb_i)\n",
    "        score_j = self.forward(price_j, fund_j, emb_j)\n",
    "        return torch.sigmoid(score_i - score_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Robust Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_robust_metrics(daily_returns, annualize=True):\n",
    "    \"\"\"Compute multiple robust metrics from daily strategy returns.\n",
    "    \n",
    "    Args:\n",
    "        daily_returns: array of daily returns\n",
    "        annualize: whether to annualize Sharpe/Sortino\n",
    "    \n",
    "    Returns:\n",
    "        dict with various metrics\n",
    "    \"\"\"\n",
    "    returns = np.array(daily_returns)\n",
    "    n_days = len(returns)\n",
    "    \n",
    "    if n_days < 10:\n",
    "        return {k: 0.0 for k in ['sharpe', 'winsorized_sharpe', 'sortino', 'cvar_5', 'cvar_10', 'mean_return', 'std_return']}\n",
    "    \n",
    "    factor = np.sqrt(252) if annualize else 1.0\n",
    "    \n",
    "    # 1. Standard Sharpe\n",
    "    mean_ret = np.mean(returns)\n",
    "    std_ret = np.std(returns)\n",
    "    sharpe = (mean_ret / std_ret * factor) if std_ret > 0 else 0.0\n",
    "    \n",
    "    # 2. Winsorized Sharpe (clip at 5th/95th percentile)\n",
    "    p5, p95 = np.percentile(returns, [5, 95])\n",
    "    winsorized = np.clip(returns, p5, p95)\n",
    "    win_mean = np.mean(winsorized)\n",
    "    win_std = np.std(winsorized)\n",
    "    winsorized_sharpe = (win_mean / win_std * factor) if win_std > 0 else 0.0\n",
    "    \n",
    "    # 3. Sortino Ratio (downside deviation only)\n",
    "    downside_returns = returns[returns < 0]\n",
    "    if len(downside_returns) > 0:\n",
    "        downside_std = np.std(downside_returns)\n",
    "        sortino = (mean_ret / downside_std * factor) if downside_std > 0 else 0.0\n",
    "    else:\n",
    "        sortino = float('inf') if mean_ret > 0 else 0.0\n",
    "    \n",
    "    # 4. CVaR (Expected Shortfall) at 5% - average of worst 5% of days\n",
    "    n_tail = max(1, int(n_days * 0.05))\n",
    "    sorted_returns = np.sort(returns)\n",
    "    cvar_5 = np.mean(sorted_returns[:n_tail])  # Average of worst 5%\n",
    "    \n",
    "    # 5. CVaR at 10%\n",
    "    n_tail_10 = max(1, int(n_days * 0.10))\n",
    "    cvar_10 = np.mean(sorted_returns[:n_tail_10])\n",
    "    \n",
    "    return {\n",
    "        'sharpe': sharpe,\n",
    "        'winsorized_sharpe': winsorized_sharpe,\n",
    "        'sortino': sortino,\n",
    "        'cvar_5': cvar_5,  # More negative = worse\n",
    "        'cvar_10': cvar_10,\n",
    "        'mean_return': mean_ret,\n",
    "        'std_return': std_ret,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_scores(model, df, price_cols, fund_cols, emb_cols, device, batch_size=1024):\n",
    "    model.eval()\n",
    "    price_arr = torch.tensor(df[price_cols].values.astype(np.float32))\n",
    "    fund_arr = torch.tensor(df[fund_cols].values.astype(np.float32))\n",
    "    emb_arr = torch.tensor(df[emb_cols].values.astype(np.float32))\n",
    "    \n",
    "    scores = []\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        price = price_arr[i:i+batch_size].to(device)\n",
    "        fund = fund_arr[i:i+batch_size].to(device)\n",
    "        emb = emb_arr[i:i+batch_size].to(device)\n",
    "        score = model(price, fund, emb)\n",
    "        scores.append(score.cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(scores)\n",
    "\n",
    "\n",
    "def evaluate_model(model, df, price_cols, fund_cols, emb_cols, device, k=5):\n",
    "    \"\"\"Compute all metrics including robust tail metrics.\"\"\"\n",
    "    df_eval = df.copy()\n",
    "    df_eval[\"score\"] = get_scores(model, df_eval, price_cols, fund_cols, emb_cols, device)\n",
    "    \n",
    "    # IC Sharpe (rank-based)\n",
    "    ics = []\n",
    "    for date, group in df_eval.groupby(\"feature_date\"):\n",
    "        if len(group) < 10:\n",
    "            continue\n",
    "        ic, _ = spearmanr(group[\"score\"], group[\"simple_return\"])\n",
    "        if not np.isnan(ic):\n",
    "            ics.append(ic)\n",
    "    \n",
    "    mean_ic = np.mean(ics) if ics else 0\n",
    "    ic_std = np.std(ics) if ics else 1\n",
    "    ic_sharpe = mean_ic / ic_std * np.sqrt(252) if ic_std > 0 else 0\n",
    "    \n",
    "    # Daily short strategy returns (unclipped for realistic eval)\n",
    "    daily_returns = []\n",
    "    for date, group in df_eval.groupby(\"feature_date\"):\n",
    "        if len(group) < 10:\n",
    "            continue\n",
    "        bottom = group.nsmallest(k, \"score\")\n",
    "        short_ret = -bottom[\"simple_return\"].mean()  # Short = negative of return\n",
    "        daily_returns.append(short_ret)\n",
    "    \n",
    "    # Compute robust metrics\n",
    "    robust = compute_robust_metrics(daily_returns)\n",
    "    \n",
    "    return {\n",
    "        'ic_sharpe': ic_sharpe,\n",
    "        'mean_ic': mean_ic,\n",
    "        **robust,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample metrics with outliers:\n",
      "  sharpe: 0.1042\n",
      "  winsorized_sharpe: 0.7324\n",
      "  sortino: 0.0943\n",
      "  cvar_5: -0.0757\n",
      "  cvar_10: -0.0503\n",
      "  mean_return: 0.0003\n",
      "  std_return: 0.0415\n"
     ]
    }
   ],
   "source": [
    "# Test robust metrics on sample data\n",
    "np.random.seed(42)\n",
    "sample_returns = np.random.normal(0.001, 0.02, 252)  # ~1yr of daily returns\n",
    "# Add a few outliers\n",
    "sample_returns[10] = -0.50  # 50% loss day\n",
    "sample_returns[100] = 0.30  # 30% gain day\n",
    "\n",
    "metrics = compute_robust_metrics(sample_returns)\n",
    "print(\"Sample metrics with outliers:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_ranking_loss(pred_prob, label, smoothing=0.1):\n",
    "    smoothed_label = label * (1 - smoothing) + 0.5 * smoothing\n",
    "    return F.binary_cross_entropy(pred_prob, smoothed_label)\n",
    "\n",
    "\n",
    "def train_epoch(model, loader, optimizer, device, label_smoothing=0.1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        price_i = batch[\"price_i\"].to(device)\n",
    "        price_j = batch[\"price_j\"].to(device)\n",
    "        fund_i = batch[\"fund_i\"].to(device)\n",
    "        fund_j = batch[\"fund_j\"].to(device)\n",
    "        emb_i = batch[\"emb_i\"].to(device)\n",
    "        emb_j = batch[\"emb_j\"].to(device)\n",
    "        label = batch[\"label\"].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_prob = model.forward_pair(price_i, fund_i, emb_i, price_j, fund_j, emb_j)\n",
    "        loss = pairwise_ranking_loss(pred_prob, label, smoothing=label_smoothing)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * len(label)\n",
    "        total_samples += len(label)\n",
    "    \n",
    "    return total_loss / total_samples\n",
    "\n",
    "\n",
    "def train_and_evaluate(config, train_dataset, val_df_news, selection_metric='winsorized_sharpe', n_epochs=15, verbose=False):\n",
    "    \"\"\"Train model, select best checkpoint by specified metric.\"\"\"\n",
    "    model = MultiBranchRanker(config).to(device)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=config.learning_rate, \n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    \n",
    "    best_metric = -float('inf')\n",
    "    best_state = None\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        train_dataset.resample_pairs()\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, device, config.label_smoothing)\n",
    "        scheduler.step()\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0 or epoch == n_epochs - 1:\n",
    "            metrics = evaluate_model(model, val_df_news, price_feat_cols, fund_feat_cols, emb_cols, device)\n",
    "            \n",
    "            # For CVaR, higher (less negative) is better\n",
    "            current = metrics[selection_metric]\n",
    "            if current > best_metric:\n",
    "                best_metric = current\n",
    "                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  Epoch {epoch+1}: {selection_metric}={current:.3f}\")\n",
    "    \n",
    "    model.load_state_dict(best_state)\n",
    "    final_metrics = evaluate_model(model, val_df_news, price_feat_cols, fund_feat_cols, emb_cols, device)\n",
    "    \n",
    "    return final_metrics, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to news-only: 339,872 rows\n",
      "Generated 169,737 pairs\n"
     ]
    }
   ],
   "source": [
    "# Create training dataset\n",
    "train_dataset = SinglePairDataset(train_df, price_feat_cols, fund_feat_cols, emb_cols, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture configs: 27\n"
     ]
    }
   ],
   "source": [
    "SEARCH_SPACE = {\n",
    "    # Architecture\n",
    "    \"latent_scale\": [0.5, 1.0, 2.0],\n",
    "    \"hidden_scale\": [0.5, 1.0, 1.5],\n",
    "    \"news_alpha\": [0.6, 0.8, 1.0],\n",
    "    # Training\n",
    "    \"learning_rate\": [5e-4, 1e-3, 2e-3],\n",
    "    \"weight_decay\": [1e-4, 1e-3, 1e-2],\n",
    "    \"label_smoothing\": [0.05, 0.1, 0.15],\n",
    "    # Dropout\n",
    "    \"fund_dropout\": [0.4, 0.5, 0.6, 0.7],\n",
    "    \"price_dropout\": [0.2, 0.3, 0.4],\n",
    "    \"news_dropout\": [0.1, 0.2, 0.3],\n",
    "}\n",
    "\n",
    "# Selection metrics to test\n",
    "SELECTION_METRICS = ['winsorized_sharpe', 'cvar_5', 'sortino', 'ic_sharpe']\n",
    "\n",
    "n_arch = len(SEARCH_SPACE[\"latent_scale\"]) * len(SEARCH_SPACE[\"hidden_scale\"]) * len(SEARCH_SPACE[\"news_alpha\"])\n",
    "print(f\"Architecture configs: {n_arch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Selection Metrics\n",
    "\n",
    "Run architecture search with each selection metric to see which finds best configs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARING SELECTION METRICS\n",
      "======================================================================\n",
      "Running architecture search with each metric...\n",
      "[ 1/27] l=0.5 h=0.5 a=0.6 | WinSharpe=2.46 CVaR5=-0.477 Sortino=0.13 IC=3.83 | 136s\n",
      "[ 2/27] l=0.5 h=0.5 a=0.8 | WinSharpe=1.70 CVaR5=-0.462 Sortino=-0.15 IC=3.99 | 131s\n",
      "[ 3/27] l=0.5 h=0.5 a=1.0 | WinSharpe=1.40 CVaR5=-0.502 Sortino=-0.37 IC=3.99 | 133s\n",
      "[ 4/27] l=0.5 h=1.0 a=0.6 | WinSharpe=2.15 CVaR5=-0.481 Sortino=0.01 IC=3.86 | 143s\n",
      "[ 5/27] l=0.5 h=1.0 a=0.8 | WinSharpe=2.55 CVaR5=-0.467 Sortino=0.01 IC=4.93 | 149s\n",
      "[ 6/27] l=0.5 h=1.0 a=1.0 | WinSharpe=2.82 CVaR5=-0.445 Sortino=0.16 IC=4.80 | 143s\n",
      "[ 7/27] l=0.5 h=1.5 a=0.6 | WinSharpe=2.24 CVaR5=-0.502 Sortino=0.13 IC=4.29 | 152s\n",
      "[ 8/27] l=0.5 h=1.5 a=0.8 | WinSharpe=2.76 CVaR5=-0.462 Sortino=0.16 IC=3.31 | 155s\n",
      "[ 9/27] l=0.5 h=1.5 a=1.0 | WinSharpe=1.65 CVaR5=-0.496 Sortino=-0.14 IC=5.28 | 152s\n",
      "[10/27] l=1.0 h=0.5 a=0.6 | WinSharpe=2.05 CVaR5=-0.473 Sortino=0.14 IC=3.44 | 134s\n",
      "[11/27] l=1.0 h=0.5 a=0.8 | WinSharpe=1.55 CVaR5=-0.499 Sortino=-0.26 IC=3.89 | 136s\n",
      "[12/27] l=1.0 h=0.5 a=1.0 | WinSharpe=2.10 CVaR5=-0.509 Sortino=-0.23 IC=3.38 | 138s\n",
      "[13/27] l=1.0 h=1.0 a=0.6 | WinSharpe=2.44 CVaR5=-0.451 Sortino=0.08 IC=4.31 | 150s\n",
      "[14/27] l=1.0 h=1.0 a=0.8 | WinSharpe=1.93 CVaR5=-0.476 Sortino=-0.04 IC=3.81 | 144s\n",
      "[15/27] l=1.0 h=1.0 a=1.0 | WinSharpe=1.53 CVaR5=-0.502 Sortino=-0.20 IC=3.72 | 143s\n",
      "[16/27] l=1.0 h=1.5 a=0.6 | WinSharpe=1.53 CVaR5=-0.478 Sortino=-0.11 IC=3.51 | 153s\n",
      "[17/27] l=1.0 h=1.5 a=0.8 | WinSharpe=2.31 CVaR5=-0.429 Sortino=-0.03 IC=3.70 | 154s\n",
      "[18/27] l=1.0 h=1.5 a=1.0 | WinSharpe=1.28 CVaR5=-0.498 Sortino=-0.48 IC=3.47 | 159s\n",
      "[19/27] l=2.0 h=0.5 a=0.6 | WinSharpe=2.69 CVaR5=-0.502 Sortino=0.26 IC=3.97 | 139s\n",
      "[20/27] l=2.0 h=0.5 a=0.8 | WinSharpe=1.77 CVaR5=-0.478 Sortino=-0.21 IC=4.32 | 136s\n",
      "[21/27] l=2.0 h=0.5 a=1.0 | WinSharpe=1.83 CVaR5=-0.467 Sortino=-0.34 IC=3.56 | 135s\n",
      "[22/27] l=2.0 h=1.0 a=0.6 | WinSharpe=2.48 CVaR5=-0.499 Sortino=0.10 IC=2.93 | 149s\n",
      "[23/27] l=2.0 h=1.0 a=0.8 | WinSharpe=1.90 CVaR5=-0.498 Sortino=-0.21 IC=3.72 | 146s\n",
      "[24/27] l=2.0 h=1.0 a=1.0 | WinSharpe=1.66 CVaR5=-0.487 Sortino=-0.33 IC=4.79 | 155s\n",
      "[25/27] l=2.0 h=1.5 a=0.6 | WinSharpe=1.45 CVaR5=-0.483 Sortino=-0.40 IC=3.91 | 156s\n",
      "[26/27] l=2.0 h=1.5 a=0.8 | WinSharpe=1.55 CVaR5=-0.472 Sortino=-0.16 IC=3.13 | 155s\n"
     ]
    }
   ],
   "source": [
    "print(\"COMPARING SELECTION METRICS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Running architecture search with each metric...\")\n",
    "\n",
    "arch_configs = list(product(\n",
    "    SEARCH_SPACE[\"latent_scale\"],\n",
    "    SEARCH_SPACE[\"hidden_scale\"],\n",
    "    SEARCH_SPACE[\"news_alpha\"],\n",
    "))\n",
    "\n",
    "# Store results for each selection metric\n",
    "metric_results = {m: [] for m in SELECTION_METRICS}\n",
    "\n",
    "for i, (latent_scale, hidden_scale, news_alpha) in enumerate(arch_configs):\n",
    "    config = ModelConfig(\n",
    "        n_fundamental_features=len(fund_feat_cols),\n",
    "        n_price_features=len(price_feat_cols),\n",
    "        n_embedding_dim=len(emb_cols),\n",
    "        fund_hidden=int(64 * hidden_scale),\n",
    "        price_hidden=int(32 * hidden_scale),\n",
    "        news_hidden=int(128 * hidden_scale),\n",
    "        fundamental_latent=int(32 * latent_scale),\n",
    "        price_latent=int(16 * latent_scale),\n",
    "        news_latent=int(32 * latent_scale),\n",
    "        news_alpha=news_alpha,\n",
    "    )\n",
    "    \n",
    "    # Train with winsorized_sharpe (our main metric)\n",
    "    start = datetime.now()\n",
    "    metrics, _ = train_and_evaluate(config, train_dataset, val_df_news, \n",
    "                                     selection_metric='winsorized_sharpe', n_epochs=15)\n",
    "    elapsed = (datetime.now() - start).total_seconds()\n",
    "    \n",
    "    result = {\n",
    "        \"latent_scale\": latent_scale,\n",
    "        \"hidden_scale\": hidden_scale,\n",
    "        \"news_alpha\": news_alpha,\n",
    "        **metrics,\n",
    "    }\n",
    "    \n",
    "    # Store for all metrics\n",
    "    for m in SELECTION_METRICS:\n",
    "        metric_results[m].append(result)\n",
    "    \n",
    "    print(f\"[{i+1:2d}/{len(arch_configs)}] l={latent_scale:.1f} h={hidden_scale:.1f} a={news_alpha:.1f} | \"\n",
    "          f\"WinSharpe={metrics['winsorized_sharpe']:.2f} CVaR5={metrics['cvar_5']:.3f} \"\n",
    "          f\"Sortino={metrics['sortino']:.2f} IC={metrics['ic_sharpe']:.2f} | {elapsed:.0f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare best configs found by each metric\n",
    "print(\"\\nBEST CONFIGS BY EACH SELECTION METRIC:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "best_by_metric = {}\n",
    "for metric in SELECTION_METRICS:\n",
    "    df_results = pd.DataFrame(metric_results[metric])\n",
    "    \n",
    "    # For CVaR, higher (less negative) is better\n",
    "    best_idx = df_results[metric].idxmax()\n",
    "    best = df_results.loc[best_idx]\n",
    "    best_by_metric[metric] = best\n",
    "    \n",
    "    print(f\"\\n{metric}:\")\n",
    "    print(f\"  Best config: latent={best['latent_scale']}, hidden={best['hidden_scale']}, alpha={best['news_alpha']}\")\n",
    "    print(f\"  Metrics: WinSharpe={best['winsorized_sharpe']:.2f}, CVaR5={best['cvar_5']:.3f}, \"\n",
    "          f\"Sortino={best['sortino']:.2f}, IC={best['ic_sharpe']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between metrics\n",
    "df_all = pd.DataFrame(metric_results['winsorized_sharpe'])\n",
    "corr_cols = ['ic_sharpe', 'sharpe', 'winsorized_sharpe', 'sortino', 'cvar_5', 'cvar_10']\n",
    "\n",
    "print(\"\\nMETRIC CORRELATIONS:\")\n",
    "print(df_all[corr_cols].corr().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize metric relationships\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# IC Sharpe vs Winsorized Sharpe\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(df_all['ic_sharpe'], df_all['winsorized_sharpe'], alpha=0.6)\n",
    "ax.set_xlabel('IC Sharpe')\n",
    "ax.set_ylabel('Winsorized Sharpe')\n",
    "ax.set_title('IC Sharpe vs Winsorized Sharpe')\n",
    "\n",
    "# IC Sharpe vs CVaR\n",
    "ax = axes[0, 1]\n",
    "ax.scatter(df_all['ic_sharpe'], df_all['cvar_5'], alpha=0.6, c='red')\n",
    "ax.set_xlabel('IC Sharpe')\n",
    "ax.set_ylabel('CVaR 5% (higher=better)')\n",
    "ax.set_title('IC Sharpe vs CVaR 5%')\n",
    "\n",
    "# Winsorized vs Raw Sharpe\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(df_all['sharpe'], df_all['winsorized_sharpe'], alpha=0.6, c='green')\n",
    "ax.plot([df_all['sharpe'].min(), df_all['sharpe'].max()], \n",
    "        [df_all['sharpe'].min(), df_all['sharpe'].max()], 'k--', alpha=0.3)\n",
    "ax.set_xlabel('Raw Sharpe')\n",
    "ax.set_ylabel('Winsorized Sharpe')\n",
    "ax.set_title('Raw vs Winsorized Sharpe')\n",
    "\n",
    "# Sortino vs Winsorized\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(df_all['sortino'], df_all['winsorized_sharpe'], alpha=0.6, c='purple')\n",
    "ax.set_xlabel('Sortino Ratio')\n",
    "ax.set_ylabel('Winsorized Sharpe')\n",
    "ax.set_title('Sortino vs Winsorized Sharpe')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Full Optimization with Best Metric\n",
    "\n",
    "Use Winsorized Sharpe for full staged optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTION_METRIC = 'winsorized_sharpe'  # Change this to test others\n",
    "\n",
    "print(f\"\\nFULL OPTIMIZATION WITH {SELECTION_METRIC.upper()}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Best architecture from comparison\n",
    "best_arch = best_by_metric[SELECTION_METRIC]\n",
    "best_latent = best_arch['latent_scale']\n",
    "best_hidden = best_arch['hidden_scale']\n",
    "best_alpha = best_arch['news_alpha']\n",
    "\n",
    "print(f\"Best architecture: latent={best_latent}, hidden={best_hidden}, alpha={best_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Training hyperparameters\n",
    "print(\"\\nSTAGE 2: TRAINING HYPERPARAMETERS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "train_configs = list(product(\n",
    "    SEARCH_SPACE[\"learning_rate\"],\n",
    "    SEARCH_SPACE[\"weight_decay\"],\n",
    "    SEARCH_SPACE[\"label_smoothing\"],\n",
    "))\n",
    "\n",
    "train_results = []\n",
    "best_train_metric = -float('inf')\n",
    "best_train = None\n",
    "\n",
    "for i, (lr, wd, smoothing) in enumerate(train_configs):\n",
    "    config = ModelConfig(\n",
    "        n_fundamental_features=len(fund_feat_cols),\n",
    "        n_price_features=len(price_feat_cols),\n",
    "        n_embedding_dim=len(emb_cols),\n",
    "        fund_hidden=int(64 * best_hidden),\n",
    "        price_hidden=int(32 * best_hidden),\n",
    "        news_hidden=int(128 * best_hidden),\n",
    "        fundamental_latent=int(32 * best_latent),\n",
    "        price_latent=int(16 * best_latent),\n",
    "        news_latent=int(32 * best_latent),\n",
    "        news_alpha=best_alpha,\n",
    "        learning_rate=lr,\n",
    "        weight_decay=wd,\n",
    "        label_smoothing=smoothing,\n",
    "    )\n",
    "    \n",
    "    metrics, _ = train_and_evaluate(config, train_dataset, val_df_news, \n",
    "                                     selection_metric=SELECTION_METRIC, n_epochs=15)\n",
    "    \n",
    "    train_results.append({\"lr\": lr, \"wd\": wd, \"smooth\": smoothing, **metrics})\n",
    "    \n",
    "    if metrics[SELECTION_METRIC] > best_train_metric:\n",
    "        best_train_metric = metrics[SELECTION_METRIC]\n",
    "        best_train = (lr, wd, smoothing)\n",
    "    \n",
    "    print(f\"[{i+1:2d}/{len(train_configs)}] lr={lr:.0e} wd={wd:.0e} s={smoothing:.2f} | \"\n",
    "          f\"{SELECTION_METRIC}={metrics[SELECTION_METRIC]:.3f}\")\n",
    "\n",
    "best_lr, best_wd, best_smooth = best_train\n",
    "print(f\"\\nBest: lr={best_lr:.0e}, wd={best_wd:.0e}, smooth={best_smooth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3: Dropout\n",
    "print(\"\\nSTAGE 3: DROPOUT\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "dropout_configs = list(product(\n",
    "    SEARCH_SPACE[\"fund_dropout\"],\n",
    "    SEARCH_SPACE[\"price_dropout\"],\n",
    "    SEARCH_SPACE[\"news_dropout\"],\n",
    "))\n",
    "\n",
    "dropout_results = []\n",
    "best_dropout_metric = -float('inf')\n",
    "best_dropout = None\n",
    "best_model = None\n",
    "\n",
    "for i, (fund_do, price_do, news_do) in enumerate(dropout_configs):\n",
    "    config = ModelConfig(\n",
    "        n_fundamental_features=len(fund_feat_cols),\n",
    "        n_price_features=len(price_feat_cols),\n",
    "        n_embedding_dim=len(emb_cols),\n",
    "        fund_hidden=int(64 * best_hidden),\n",
    "        price_hidden=int(32 * best_hidden),\n",
    "        news_hidden=int(128 * best_hidden),\n",
    "        fundamental_latent=int(32 * best_latent),\n",
    "        price_latent=int(16 * best_latent),\n",
    "        news_latent=int(32 * best_latent),\n",
    "        news_alpha=best_alpha,\n",
    "        fundamental_dropout=fund_do,\n",
    "        price_dropout=price_do,\n",
    "        news_dropout=news_do,\n",
    "        learning_rate=best_lr,\n",
    "        weight_decay=best_wd,\n",
    "        label_smoothing=best_smooth,\n",
    "    )\n",
    "    \n",
    "    metrics, model = train_and_evaluate(config, train_dataset, val_df_news, \n",
    "                                         selection_metric=SELECTION_METRIC, n_epochs=15)\n",
    "    \n",
    "    dropout_results.append({\"fund\": fund_do, \"price\": price_do, \"news\": news_do, **metrics})\n",
    "    \n",
    "    if metrics[SELECTION_METRIC] > best_dropout_metric:\n",
    "        best_dropout_metric = metrics[SELECTION_METRIC]\n",
    "        best_dropout = (fund_do, price_do, news_do)\n",
    "        best_model = model\n",
    "    \n",
    "    print(f\"[{i+1:2d}/{len(dropout_configs)}] f={fund_do:.1f} p={price_do:.1f} n={news_do:.1f} | \"\n",
    "          f\"{SELECTION_METRIC}={metrics[SELECTION_METRIC]:.3f}\")\n",
    "\n",
    "best_fund_do, best_price_do, best_news_do = best_dropout\n",
    "print(f\"\\nBest: fund={best_fund_do}, price={best_price_do}, news={best_news_do}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTRAINING FINAL MODEL (25 epochs)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "final_config = ModelConfig(\n",
    "    n_fundamental_features=len(fund_feat_cols),\n",
    "    n_price_features=len(price_feat_cols),\n",
    "    n_embedding_dim=len(emb_cols),\n",
    "    fund_hidden=int(64 * best_hidden),\n",
    "    price_hidden=int(32 * best_hidden),\n",
    "    news_hidden=int(128 * best_hidden),\n",
    "    fundamental_latent=int(32 * best_latent),\n",
    "    price_latent=int(16 * best_latent),\n",
    "    news_latent=int(32 * best_latent),\n",
    "    news_alpha=best_alpha,\n",
    "    fundamental_dropout=best_fund_do,\n",
    "    price_dropout=best_price_do,\n",
    "    news_dropout=best_news_do,\n",
    "    learning_rate=best_lr,\n",
    "    weight_decay=best_wd,\n",
    "    label_smoothing=best_smooth,\n",
    "    n_epochs=25,\n",
    ")\n",
    "\n",
    "print(f\"Config: hidden=({final_config.fund_hidden},{final_config.price_hidden},{final_config.news_hidden})\")\n",
    "print(f\"        latent=({final_config.fundamental_latent},{final_config.price_latent},{final_config.news_latent})\")\n",
    "print(f\"        dropout=({final_config.fundamental_dropout},{final_config.price_dropout},{final_config.news_dropout})\")\n",
    "print(f\"        lr={final_config.learning_rate:.0e}, wd={final_config.weight_decay:.0e}\")\n",
    "\n",
    "final_metrics, final_model = train_and_evaluate(\n",
    "    final_config, train_dataset, val_df_news, \n",
    "    selection_metric=SELECTION_METRIC, n_epochs=25, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set evaluation\n",
    "test_metrics = evaluate_model(final_model, test_df_news, price_feat_cols, fund_feat_cols, emb_cols, device)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"IC Sharpe:         {test_metrics['ic_sharpe']:.2f}\")\n",
    "print(f\"Raw Sharpe:        {test_metrics['sharpe']:.2f}\")\n",
    "print(f\"Winsorized Sharpe: {test_metrics['winsorized_sharpe']:.2f}\")\n",
    "print(f\"Sortino:           {test_metrics['sortino']:.2f}\")\n",
    "print(f\"CVaR 5%:           {test_metrics['cvar_5']:.4f}\")\n",
    "print(f\"CVaR 10%:          {test_metrics['cvar_10']:.4f}\")\n",
    "print(f\"Mean Daily Return: {test_metrics['mean_return']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "pd.DataFrame(metric_results['winsorized_sharpe']).to_parquet(\"data/robust_arch_results2.pqt\")\n",
    "pd.DataFrame(train_results).to_parquet(\"data/robust_train_results2.pqt\")\n",
    "pd.DataFrame(dropout_results).to_parquet(\"data/robust_dropout_results2.pqt\")\n",
    "\n",
    "torch.save({\n",
    "    \"model_state_dict\": final_model.state_dict(),\n",
    "    \"config\": final_config,\n",
    "    \"price_cols\": price_feat_cols,\n",
    "    \"fund_cols\": fund_feat_cols,\n",
    "    \"emb_cols\": emb_cols,\n",
    "    \"selection_metric\": SELECTION_METRIC,\n",
    "    \"test_metrics\": test_metrics,\n",
    "}, \"data/model_robust_optimized2.pt\")\n",
    "\n",
    "print(\"Saved to data/model_robust_optimized2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Selection metric: winsorized_sharpe\n",
      "\n",
      "Best config:\n",
      "  Architecture: latent=0.5, hidden=1.5, alpha=1.0\n",
      "  Training: lr=5e-04, wd=1e-04, smooth=0.15\n",
      "  Dropout: fund=0.6, price=0.3, news=0.1\n",
      "\n",
      "Test performance:\n",
      "  Winsorized Sharpe: 3.19\n",
      "  CVaR 5%: -0.3300\n",
      "  Sortino: 1.18\n"
     ]
    }
   ],
   "source": [
    "# print(\"\\n\" + \"=\" * 60)\n",
    "# print(\"SUMMARY\")\n",
    "# print(\"=\" * 60)\n",
    "# print(f\"Selection metric: {SELECTION_METRIC}\")\n",
    "# print(f\"\\nBest config:\")\n",
    "# print(f\"  Architecture: latent={best_latent}, hidden={best_hidden}, alpha={best_alpha}\")\n",
    "# print(f\"  Training: lr={best_lr:.0e}, wd={best_wd:.0e}, smooth={best_smooth}\")\n",
    "# print(f\"  Dropout: fund={best_fund_do}, price={best_price_do}, news={best_news_do}\")\n",
    "# print(f\"\\nTest performance:\")\n",
    "# print(f\"  Winsorized Sharpe: {test_metrics['winsorized_sharpe']:.2f}\")\n",
    "# print(f\"  CVaR 5%: {test_metrics['cvar_5']:.4f}\")\n",
    "# print(f\"  Sortino: {test_metrics['sortino']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Selection metric: {SELECTION_METRIC}\")\n",
    "print(f\"\\nBest config:\")\n",
    "print(f\"  Architecture: latent={best_latent}, hidden={best_hidden}, alpha={best_alpha}\")\n",
    "print(f\"  Training: lr={best_lr:.0e}, wd={best_wd:.0e}, smooth={best_smooth}\")\n",
    "print(f\"  Dropout: fund={best_fund_do}, price={best_price_do}, news={best_news_do}\")\n",
    "print(f\"\\nTest performance:\")\n",
    "print(f\"  Winsorized Sharpe: {test_metrics['winsorized_sharpe']:.2f}\")\n",
    "print(f\"  CVaR 5%: {test_metrics['cvar_5']:.4f}\")\n",
    "print(f\"  Sortino: {test_metrics['sortino']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
