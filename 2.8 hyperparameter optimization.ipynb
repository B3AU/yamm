{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 2.8 Hyperparameter Optimization (Simple Returns)\n",
    "\n",
    "Based on best model from 2.5 (Sharpe 25). \n",
    "\n",
    "**Key Change: Simple Returns Instead of Log Returns**\n",
    "- Training target: `simple_return = exp(log_return) - 1`\n",
    "- Evaluation: NO clipping (realistic assessment)\n",
    "- This matches what backtrader actually computes\n",
    "\n",
    "**Optimizes:**\n",
    "- Architecture: latent dims, hidden sizes, news alpha\n",
    "- Training: learning rate, weight decay, label smoothing\n",
    "\n",
    "**Fixed (from 2.5 best):**\n",
    "- Dropout: fund=0.8, price=0.4, news=0.2\n",
    "- Single-pair-per-symbol training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    # Feature dimensions (fixed)\n",
    "    n_fundamental_features: int = 19\n",
    "    n_price_features: int = 9\n",
    "    n_embedding_dim: int = 768\n",
    "    \n",
    "    # Hidden layer sizes (tunable)\n",
    "    fund_hidden: int = 64\n",
    "    price_hidden: int = 32\n",
    "    news_hidden: int = 128\n",
    "    \n",
    "    # Encoder latent dimensions (tunable)\n",
    "    fundamental_latent: int = 32\n",
    "    price_latent: int = 16\n",
    "    news_latent: int = 32\n",
    "    \n",
    "    # Dropout (fixed from 2.5 best)\n",
    "    fundamental_dropout: float = 0.8\n",
    "    price_dropout: float = 0.4\n",
    "    news_dropout: float = 0.2\n",
    "    \n",
    "    # News influence (tunable)\n",
    "    news_alpha: float = 0.8\n",
    "    \n",
    "    # Training (tunable)\n",
    "    batch_size: int = 512\n",
    "    learning_rate: float = 1e-3\n",
    "    weight_decay: float = 1e-3\n",
    "    label_smoothing: float = 0.1\n",
    "    n_epochs: int = 15  # Reduced for grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 2,092,929 rows\n",
      "Date range: 2021-01-13 to 2025-12-18\n",
      "\n",
      "Return comparison:\n",
      "  Log return range:    [-10.765, 10.633]\n",
      "  Simple return range: [-1.000, 41469.588]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"data/ml_dataset.pqt\")\n",
    "df[\"feature_date\"] = pd.to_datetime(df[\"feature_date\"])\n",
    "\n",
    "# Convert log returns to simple returns for training\n",
    "# target_return is log(next_close/close), we need (next_close/close - 1)\n",
    "df[\"simple_return\"] = np.exp(df[\"target_return\"]) - 1\n",
    "\n",
    "print(f\"Dataset: {len(df):,} rows\")\n",
    "print(f\"Date range: {df['feature_date'].min().date()} to {df['feature_date'].max().date()}\")\n",
    "print(f\"\\nReturn comparison:\")\n",
    "print(f\"  Log return range:    [{df['target_return'].min():.3f}, {df['target_return'].max():.3f}]\")\n",
    "print(f\"  Simple return range: [{df['simple_return'].min():.3f}, {df['simple_return'].max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price features: 9\n",
      "Fundamental features: 19\n",
      "Embedding dims: 768\n"
     ]
    }
   ],
   "source": [
    "# Feature columns\n",
    "price_feat_cols = [\n",
    "    \"overnight_gap_z\", \"intraday_ret_z\",\n",
    "    \"ret_1d_z\", \"ret_2d_z\", \"ret_3d_z\", \"ret_5d_z\",\n",
    "    \"vol_5d_z\", \"dist_from_high_5d_z\", \"dist_from_low_5d_z\"\n",
    "]\n",
    "fund_feat_cols = [c for c in df.columns if c.endswith(\"_z\") and c not in price_feat_cols and c != \"news_count_z\"]\n",
    "emb_cols = [c for c in df.columns if c.startswith(\"emb_\")]\n",
    "\n",
    "print(f\"Price features: {len(price_feat_cols)}\")\n",
    "print(f\"Fundamental features: {len(fund_feat_cols)}\")\n",
    "print(f\"Embedding dims: {len(emb_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1,418,494 rows (2021-01-13 to 2024-05-01)\n",
      "Val: 210,247 rows (2024-05-02 to 2024-10-21)\n",
      "Test: 464,188 rows (2024-10-22 to 2025-12-18)\n",
      "\n",
      "Val (news-only): 58,882\n",
      "Test (news-only): 128,502\n"
     ]
    }
   ],
   "source": [
    "# Time-based split\n",
    "dates = sorted(df[\"feature_date\"].unique())\n",
    "n_dates = len(dates)\n",
    "train_end_idx = int(n_dates * 0.7)\n",
    "val_end_idx = int(n_dates * 0.8)\n",
    "\n",
    "train_dates = set(dates[:train_end_idx])\n",
    "val_dates = set(dates[train_end_idx:val_end_idx])\n",
    "test_dates = set(dates[val_end_idx:])\n",
    "\n",
    "train_df = df[df[\"feature_date\"].isin(train_dates)].copy()\n",
    "val_df = df[df[\"feature_date\"].isin(val_dates)].copy()\n",
    "test_df = df[df[\"feature_date\"].isin(test_dates)].copy()\n",
    "\n",
    "print(f\"Train: {len(train_df):,} rows ({min(train_dates).date()} to {max(train_dates).date()})\")\n",
    "print(f\"Val: {len(val_df):,} rows ({min(val_dates).date()} to {max(val_dates).date()})\")\n",
    "print(f\"Test: {len(test_df):,} rows ({min(test_dates).date()} to {max(test_dates).date()})\")\n",
    "\n",
    "# News-only filtering for evaluation\n",
    "def filter_news_only(df_in, emb_cols):\n",
    "    has_news = (df_in[emb_cols].abs().sum(axis=1) > 0)\n",
    "    return df_in[has_news].copy()\n",
    "\n",
    "val_df_news = filter_news_only(val_df, emb_cols)\n",
    "test_df_news = filter_news_only(test_df, emb_cols)\n",
    "print(f\"\\nVal (news-only): {len(val_df_news):,}\")\n",
    "print(f\"Test (news-only): {len(test_df_news):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 2. Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinglePairDataset(Dataset):\n",
    "    \"\"\"Dataset where each symbol appears in exactly one pair per day.\n",
    "    \n",
    "    Uses simple returns (not log returns) for training targets.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, price_cols, fund_cols, emb_cols, verbose=True):\n",
    "        has_news = (df[emb_cols].abs().sum(axis=1) > 0)\n",
    "        df_news = df[has_news].copy().reset_index(drop=True)\n",
    "        if verbose:\n",
    "            print(f\"Filtered to news-only: {len(df_news):,} rows\")\n",
    "\n",
    "        self.df = df_news\n",
    "        self.price_cols = price_cols\n",
    "        self.fund_cols = fund_cols\n",
    "        self.emb_cols = emb_cols\n",
    "\n",
    "        self.date_groups = {}\n",
    "        for date, group in self.df.groupby(\"feature_date\"):\n",
    "            indices = group.index.tolist()\n",
    "            if len(indices) >= 2:\n",
    "                self.date_groups[date] = indices\n",
    "\n",
    "        self.dates = list(self.date_groups.keys())\n",
    "\n",
    "        self.price_arr = self.df[price_cols].values.astype(np.float32)\n",
    "        self.fund_arr = self.df[fund_cols].values.astype(np.float32)\n",
    "        self.emb_arr = self.df[emb_cols].values.astype(np.float32)\n",
    "        \n",
    "        # Use simple_return instead of target_return (log)\n",
    "        self.target_arr = self.df[\"simple_return\"].values.astype(np.float32)\n",
    "\n",
    "        self.pairs = []\n",
    "        self._generate_pairs(verbose=verbose)\n",
    "\n",
    "    def _generate_pairs(self, verbose=False):\n",
    "        pairs = []\n",
    "        for date in self.dates:\n",
    "            indices = list(self.date_groups[date])\n",
    "            np.random.shuffle(indices)\n",
    "            for i in range(0, len(indices) - 1, 2):\n",
    "                pairs.append((indices[i], indices[i + 1]))\n",
    "        self.pairs = pairs\n",
    "        if verbose:\n",
    "            print(f\"Generated {len(self.pairs):,} pairs\")\n",
    "\n",
    "    def resample_pairs(self):\n",
    "        self._generate_pairs()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i, j = self.pairs[idx]\n",
    "        price_i, price_j = self.price_arr[i], self.price_arr[j]\n",
    "        fund_i, fund_j = self.fund_arr[i], self.fund_arr[j]\n",
    "        emb_i, emb_j = self.emb_arr[i], self.emb_arr[j]\n",
    "        actual_label = 1.0 if self.target_arr[i] > self.target_arr[j] else 0.0\n",
    "\n",
    "        if np.random.random() < 0.5:\n",
    "            price_i, price_j = price_j, price_i\n",
    "            fund_i, fund_j = fund_j, fund_i\n",
    "            emb_i, emb_j = emb_j, emb_i\n",
    "            label = 1.0 - actual_label\n",
    "        else:\n",
    "            label = actual_label\n",
    "\n",
    "        return {\n",
    "            \"price_i\": torch.tensor(price_i), \"price_j\": torch.tensor(price_j),\n",
    "            \"fund_i\": torch.tensor(fund_i), \"fund_j\": torch.tensor(fund_j),\n",
    "            \"emb_i\": torch.tensor(emb_i), \"emb_j\": torch.tensor(emb_j),\n",
    "            \"label\": torch.tensor(label),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBranchRanker(nn.Module):\n",
    "    \"\"\"Multi-branch ranking model with configurable architecture.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.fund_encoder = nn.Sequential(\n",
    "            nn.Linear(config.n_fundamental_features, config.fund_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.fundamental_dropout),\n",
    "            nn.Linear(config.fund_hidden, config.fundamental_latent),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.price_encoder = nn.Sequential(\n",
    "            nn.Linear(config.n_price_features, config.price_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.price_dropout),\n",
    "            nn.Linear(config.price_hidden, config.price_latent),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.news_encoder = nn.Sequential(\n",
    "            nn.Linear(config.n_embedding_dim, config.news_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.news_dropout),\n",
    "            nn.Linear(config.news_hidden, config.news_latent),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        fused_dim = config.fundamental_latent + config.price_latent + config.news_latent\n",
    "        self.output_head = nn.Sequential(\n",
    "            nn.Linear(fused_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, price, fund, emb):\n",
    "        h_f = self.fund_encoder(fund)\n",
    "        h_p = self.price_encoder(price)\n",
    "        h_n = self.news_encoder(emb)\n",
    "        h_n_scaled = self.config.news_alpha * h_n\n",
    "        h = torch.cat([h_f, h_p, h_n_scaled], dim=-1)\n",
    "        return self.output_head(h).squeeze(-1)\n",
    "    \n",
    "    def forward_pair(self, price_i, fund_i, emb_i, price_j, fund_j, emb_j):\n",
    "        score_i = self.forward(price_i, fund_i, emb_i)\n",
    "        score_j = self.forward(price_j, fund_j, emb_j)\n",
    "        return torch.sigmoid(score_i - score_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 3. Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_ranking_loss(pred_prob, label, smoothing=0.1):\n",
    "    smoothed_label = label * (1 - smoothing) + 0.5 * smoothing\n",
    "    return F.binary_cross_entropy(pred_prob, smoothed_label)\n",
    "\n",
    "\n",
    "def train_epoch(model, loader, optimizer, device, label_smoothing=0.1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        price_i = batch[\"price_i\"].to(device)\n",
    "        price_j = batch[\"price_j\"].to(device)\n",
    "        fund_i = batch[\"fund_i\"].to(device)\n",
    "        fund_j = batch[\"fund_j\"].to(device)\n",
    "        emb_i = batch[\"emb_i\"].to(device)\n",
    "        emb_j = batch[\"emb_j\"].to(device)\n",
    "        label = batch[\"label\"].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_prob = model.forward_pair(price_i, fund_i, emb_i, price_j, fund_j, emb_j)\n",
    "        loss = pairwise_ranking_loss(pred_prob, label, smoothing=label_smoothing)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * len(label)\n",
    "        total_samples += len(label)\n",
    "    \n",
    "    return total_loss / total_samples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_scores(model, df, price_cols, fund_cols, emb_cols, device, batch_size=1024):\n",
    "    model.eval()\n",
    "    price_arr = torch.tensor(df[price_cols].values.astype(np.float32))\n",
    "    fund_arr = torch.tensor(df[fund_cols].values.astype(np.float32))\n",
    "    emb_arr = torch.tensor(df[emb_cols].values.astype(np.float32))\n",
    "    \n",
    "    scores = []\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        price = price_arr[i:i+batch_size].to(device)\n",
    "        fund = fund_arr[i:i+batch_size].to(device)\n",
    "        emb = emb_arr[i:i+batch_size].to(device)\n",
    "        score = model(price, fund, emb)\n",
    "        scores.append(score.cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(scores)\n",
    "\n",
    "\n",
    "def evaluate_model(model, df, price_cols, fund_cols, emb_cols, device):\n",
    "    \"\"\"Compute IC Sharpe and short strategy Sharpe using SIMPLE returns (no clipping).\"\"\"\n",
    "    df_eval = df.copy()\n",
    "    df_eval[\"score\"] = get_scores(model, df_eval, price_cols, fund_cols, emb_cols, device)\n",
    "    \n",
    "    # IC - use simple_return for correlation\n",
    "    ics = []\n",
    "    for date, group in df_eval.groupby(\"feature_date\"):\n",
    "        if len(group) < 10:\n",
    "            continue\n",
    "        ic, _ = spearmanr(group[\"score\"], group[\"simple_return\"])\n",
    "        if not np.isnan(ic):\n",
    "            ics.append(ic)\n",
    "    \n",
    "    mean_ic = np.mean(ics) if ics else 0\n",
    "    ic_std = np.std(ics) if ics else 1\n",
    "    ic_sharpe = mean_ic / ic_std * np.sqrt(252) if ic_std > 0 else 0\n",
    "    \n",
    "    # Short strategy - NO CLIPPING (realistic)\n",
    "    returns = []\n",
    "    for date, group in df_eval.groupby(\"feature_date\"):\n",
    "        if len(group) < 10:\n",
    "            continue\n",
    "        bottom = group.nsmallest(5, \"score\")\n",
    "        # Use simple_return, NO clipping\n",
    "        short_ret = -bottom[\"simple_return\"].mean()\n",
    "        returns.append(short_ret)\n",
    "    \n",
    "    if len(returns) > 1:\n",
    "        short_sharpe = np.mean(returns) / np.std(returns) * np.sqrt(252)\n",
    "    else:\n",
    "        short_sharpe = 0\n",
    "    \n",
    "    return {\"mean_ic\": mean_ic, \"ic_sharpe\": ic_sharpe, \"short_sharpe\": short_sharpe}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full grid search would be: 729 combinations\n",
      "\n",
      "We'll use a staged approach instead.\n"
     ]
    }
   ],
   "source": [
    "# Search space\n",
    "SEARCH_SPACE = {\n",
    "    # Architecture - latent dimensions\n",
    "    \"latent_scale\": [0.5, 1.0, 2.0],  # Multiplier for default latent dims (32, 16, 32)\n",
    "    \n",
    "    # Architecture - hidden layer scale\n",
    "    \"hidden_scale\": [0.5, 1.0, 1.5],  # Multiplier for default hidden dims (64, 32, 128)\n",
    "    \n",
    "    # News alpha\n",
    "    \"news_alpha\": [0.5, 0.8, 1.0],\n",
    "    \n",
    "    # Training\n",
    "    \"learning_rate\": [5e-4, 1e-3, 2e-3],\n",
    "    \"weight_decay\": [1e-4, 1e-3, 1e-2],\n",
    "    \"label_smoothing\": [0.05, 0.1, 0.15],\n",
    "}\n",
    "\n",
    "# Calculate total combinations (full grid would be huge)\n",
    "total_full = 1\n",
    "for k, v in SEARCH_SPACE.items():\n",
    "    total_full *= len(v)\n",
    "print(f\"Full grid search would be: {total_full} combinations\")\n",
    "print(\"\\nWe'll use a staged approach instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to news-only: 339,872 rows\n",
      "Generated 169,737 pairs\n"
     ]
    }
   ],
   "source": [
    "# Create training dataset once\n",
    "train_dataset = SinglePairDataset(train_df, price_feat_cols, fund_feat_cols, emb_cols, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 5. Stage 1: Architecture Search (Latent & Hidden Dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_config(config, train_dataset, val_df_news, n_epochs=15, verbose=False):\n",
    "    \"\"\"Train a single configuration and return validation metrics.\"\"\"\n",
    "    model = MultiBranchRanker(config).to(device)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=config.learning_rate, \n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    \n",
    "    best_ic_sharpe = -float('inf')\n",
    "    best_state = None\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        train_dataset.resample_pairs()\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, device, config.label_smoothing)\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Evaluate every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0 or epoch == n_epochs - 1:\n",
    "            metrics = evaluate_model(model, val_df_news, price_feat_cols, fund_feat_cols, emb_cols, device)\n",
    "            if metrics[\"ic_sharpe\"] > best_ic_sharpe:\n",
    "                best_ic_sharpe = metrics[\"ic_sharpe\"]\n",
    "                best_state = model.state_dict().copy()\n",
    "            if verbose:\n",
    "                print(f\"  Epoch {epoch+1}: IC_sharpe={metrics['ic_sharpe']:.2f}\")\n",
    "    \n",
    "    model.load_state_dict(best_state)\n",
    "    final_metrics = evaluate_model(model, val_df_news, price_feat_cols, fund_feat_cols, emb_cols, device)\n",
    "    \n",
    "    return final_metrics, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAGE 1: Architecture Search\n",
      "======================================================================\n",
      "Testing 27 architecture configurations...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stage 1: Architecture search\n",
    "print(\"STAGE 1: Architecture Search\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "arch_configs = list(product(\n",
    "    SEARCH_SPACE[\"latent_scale\"],\n",
    "    SEARCH_SPACE[\"hidden_scale\"],\n",
    "    SEARCH_SPACE[\"news_alpha\"],\n",
    "))\n",
    "\n",
    "print(f\"Testing {len(arch_configs)} architecture configurations...\\n\")\n",
    "\n",
    "arch_results = []\n",
    "best_arch_sharpe = -float('inf')\n",
    "best_arch_config = None\n",
    "\n",
    "for i, (latent_scale, hidden_scale, news_alpha) in enumerate(arch_configs):\n",
    "    config = ModelConfig(\n",
    "        n_fundamental_features=len(fund_feat_cols),\n",
    "        n_price_features=len(price_feat_cols),\n",
    "        n_embedding_dim=len(emb_cols),\n",
    "        # Scaled architecture\n",
    "        fund_hidden=int(64 * hidden_scale),\n",
    "        price_hidden=int(32 * hidden_scale),\n",
    "        news_hidden=int(128 * hidden_scale),\n",
    "        fundamental_latent=int(32 * latent_scale),\n",
    "        price_latent=int(16 * latent_scale),\n",
    "        news_latent=int(32 * latent_scale),\n",
    "        news_alpha=news_alpha,\n",
    "        # Fixed from 2.5 best\n",
    "        fundamental_dropout=0.8,\n",
    "        price_dropout=0.4,\n",
    "        news_dropout=0.2,\n",
    "        # Default training params\n",
    "        learning_rate=1e-3,\n",
    "        weight_decay=1e-3,\n",
    "        label_smoothing=0.1,\n",
    "    )\n",
    "    \n",
    "    start = datetime.now()\n",
    "    metrics, _ = train_config(config, train_dataset, val_df_news, n_epochs=15)\n",
    "    elapsed = (datetime.now() - start).total_seconds()\n",
    "    \n",
    "    result = {\n",
    "        \"latent_scale\": latent_scale,\n",
    "        \"hidden_scale\": hidden_scale,\n",
    "        \"news_alpha\": news_alpha,\n",
    "        **metrics,\n",
    "    }\n",
    "    arch_results.append(result)\n",
    "    \n",
    "    if metrics[\"ic_sharpe\"] > best_arch_sharpe:\n",
    "        best_arch_sharpe = metrics[\"ic_sharpe\"]\n",
    "        best_arch_config = (latent_scale, hidden_scale, news_alpha)\n",
    "    \n",
    "    print(f\"[{i+1:2d}/{len(arch_configs)}] latent={latent_scale:.1f} hidden={hidden_scale:.1f} alpha={news_alpha:.1f} | \"\n",
    "          f\"IC_sharpe={metrics['ic_sharpe']:5.2f} short_sharpe={metrics['short_sharpe']:5.2f} | {elapsed:.0f}s\")\n",
    "\n",
    "print(f\"\\nBest architecture: latent_scale={best_arch_config[0]}, hidden_scale={best_arch_config[1]}, news_alpha={best_arch_config[2]}\")\n",
    "print(f\"Best IC Sharpe: {best_arch_sharpe:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show architecture results\n",
    "arch_df = pd.DataFrame(arch_results).sort_values(\"ic_sharpe\", ascending=False)\n",
    "print(\"\\nTop 10 Architecture Configurations:\")\n",
    "print(arch_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 6. Stage 2: Training Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Training params with best architecture\n",
    "print(\"\\nSTAGE 2: Training Hyperparameter Search\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "best_latent, best_hidden, best_alpha = best_arch_config\n",
    "\n",
    "train_configs = list(product(\n",
    "    SEARCH_SPACE[\"learning_rate\"],\n",
    "    SEARCH_SPACE[\"weight_decay\"],\n",
    "    SEARCH_SPACE[\"label_smoothing\"],\n",
    "))\n",
    "\n",
    "print(f\"Testing {len(train_configs)} training configurations with best architecture...\\n\")\n",
    "\n",
    "train_results = []\n",
    "best_train_sharpe = -float('inf')\n",
    "best_train_config = None\n",
    "best_model = None\n",
    "\n",
    "for i, (lr, wd, smoothing) in enumerate(train_configs):\n",
    "    config = ModelConfig(\n",
    "        n_fundamental_features=len(fund_feat_cols),\n",
    "        n_price_features=len(price_feat_cols),\n",
    "        n_embedding_dim=len(emb_cols),\n",
    "        # Best architecture from Stage 1\n",
    "        fund_hidden=int(64 * best_hidden),\n",
    "        price_hidden=int(32 * best_hidden),\n",
    "        news_hidden=int(128 * best_hidden),\n",
    "        fundamental_latent=int(32 * best_latent),\n",
    "        price_latent=int(16 * best_latent),\n",
    "        news_latent=int(32 * best_latent),\n",
    "        news_alpha=best_alpha,\n",
    "        # Fixed dropout\n",
    "        fundamental_dropout=0.8,\n",
    "        price_dropout=0.4,\n",
    "        news_dropout=0.2,\n",
    "        # Tuned training params\n",
    "        learning_rate=lr,\n",
    "        weight_decay=wd,\n",
    "        label_smoothing=smoothing,\n",
    "    )\n",
    "    \n",
    "    start = datetime.now()\n",
    "    metrics, model = train_config(config, train_dataset, val_df_news, n_epochs=15)\n",
    "    elapsed = (datetime.now() - start).total_seconds()\n",
    "    \n",
    "    result = {\n",
    "        \"learning_rate\": lr,\n",
    "        \"weight_decay\": wd,\n",
    "        \"label_smoothing\": smoothing,\n",
    "        **metrics,\n",
    "    }\n",
    "    train_results.append(result)\n",
    "    \n",
    "    if metrics[\"ic_sharpe\"] > best_train_sharpe:\n",
    "        best_train_sharpe = metrics[\"ic_sharpe\"]\n",
    "        best_train_config = (lr, wd, smoothing)\n",
    "        best_model = model\n",
    "    \n",
    "    print(f\"[{i+1:2d}/{len(train_configs)}] lr={lr:.0e} wd={wd:.0e} smooth={smoothing:.2f} | \"\n",
    "          f\"IC_sharpe={metrics['ic_sharpe']:5.2f} short_sharpe={metrics['short_sharpe']:5.2f} | {elapsed:.0f}s\")\n",
    "\n",
    "print(f\"\\nBest training config: lr={best_train_config[0]:.0e}, wd={best_train_config[1]:.0e}, smooth={best_train_config[2]}\")\n",
    "print(f\"Best IC Sharpe: {best_train_sharpe:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training results\n",
    "train_df_results = pd.DataFrame(train_results).sort_values(\"ic_sharpe\", ascending=False)\n",
    "print(\"\\nTop 10 Training Configurations:\")\n",
    "print(train_df_results.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 7. Final Model with Best Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with more epochs\n",
    "print(\"\\nTRAINING FINAL MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "best_lr, best_wd, best_smooth = best_train_config\n",
    "\n",
    "final_config = ModelConfig(\n",
    "    n_fundamental_features=len(fund_feat_cols),\n",
    "    n_price_features=len(price_feat_cols),\n",
    "    n_embedding_dim=len(emb_cols),\n",
    "    # Best architecture\n",
    "    fund_hidden=int(64 * best_hidden),\n",
    "    price_hidden=int(32 * best_hidden),\n",
    "    news_hidden=int(128 * best_hidden),\n",
    "    fundamental_latent=int(32 * best_latent),\n",
    "    price_latent=int(16 * best_latent),\n",
    "    news_latent=int(32 * best_latent),\n",
    "    news_alpha=best_alpha,\n",
    "    # Fixed dropout\n",
    "    fundamental_dropout=0.8,\n",
    "    price_dropout=0.4,\n",
    "    news_dropout=0.2,\n",
    "    # Best training params\n",
    "    learning_rate=best_lr,\n",
    "    weight_decay=best_wd,\n",
    "    label_smoothing=best_smooth,\n",
    "    n_epochs=25,  # More epochs for final model\n",
    ")\n",
    "\n",
    "print(f\"Final config:\")\n",
    "print(f\"  Architecture: fund_hidden={final_config.fund_hidden}, price_hidden={final_config.price_hidden}, news_hidden={final_config.news_hidden}\")\n",
    "print(f\"  Latent: fund={final_config.fundamental_latent}, price={final_config.price_latent}, news={final_config.news_latent}\")\n",
    "print(f\"  News alpha: {final_config.news_alpha}\")\n",
    "print(f\"  Training: lr={final_config.learning_rate:.0e}, wd={final_config.weight_decay:.0e}, smooth={final_config.label_smoothing}\")\n",
    "\n",
    "final_metrics, final_model = train_config(final_config, train_dataset, val_df_news, n_epochs=25, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_metrics = evaluate_model(final_model, test_df_news, price_feat_cols, fund_feat_cols, emb_cols, device)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL MODEL - TEST SET RESULTS (NEWS-ONLY)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Mean IC:       {test_metrics['mean_ic']:.4f}\")\n",
    "print(f\"IC Sharpe:     {test_metrics['ic_sharpe']:.2f}\")\n",
    "print(f\"Short Sharpe:  {test_metrics['short_sharpe']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## 8. Compare with Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline (original 2.5 config) for comparison\n",
    "print(\"\\nTraining baseline (2.5 config) for comparison...\")\n",
    "\n",
    "baseline_config = ModelConfig(\n",
    "    n_fundamental_features=len(fund_feat_cols),\n",
    "    n_price_features=len(price_feat_cols),\n",
    "    n_embedding_dim=len(emb_cols),\n",
    "    # Original 2.5 architecture\n",
    "    fund_hidden=64,\n",
    "    price_hidden=32,\n",
    "    news_hidden=128,\n",
    "    fundamental_latent=32,\n",
    "    price_latent=16,\n",
    "    news_latent=32,\n",
    "    news_alpha=0.8,\n",
    "    # Same dropout\n",
    "    fundamental_dropout=0.8,\n",
    "    price_dropout=0.4,\n",
    "    news_dropout=0.2,\n",
    "    # Original training params\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=1e-3,\n",
    "    label_smoothing=0.1,\n",
    ")\n",
    "\n",
    "baseline_metrics, _ = train_config(baseline_config, train_dataset, val_df_news, n_epochs=25)\n",
    "baseline_test = evaluate_model(_, test_df_news, price_feat_cols, fund_feat_cols, emb_cols, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARISON: OPTIMIZED vs BASELINE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Metric':<20} {'Baseline':>12} {'Optimized':>12} {'Improvement':>12}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'IC Sharpe':<20} {baseline_test['ic_sharpe']:>12.2f} {test_metrics['ic_sharpe']:>12.2f} {test_metrics['ic_sharpe'] - baseline_test['ic_sharpe']:>+12.2f}\")\n",
    "print(f\"{'Short Sharpe':<20} {baseline_test['short_sharpe']:>12.2f} {test_metrics['short_sharpe']:>12.2f} {test_metrics['short_sharpe'] - baseline_test['short_sharpe']:>+12.2f}\")\n",
    "print(f\"{'Mean IC':<20} {baseline_test['mean_ic']:>12.4f} {test_metrics['mean_ic']:>12.4f} {test_metrics['mean_ic'] - baseline_test['mean_ic']:>+12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results\n",
    "all_results = {\n",
    "    \"architecture_search\": arch_results,\n",
    "    \"training_search\": train_results,\n",
    "    \"best_config\": {\n",
    "        \"latent_scale\": best_latent,\n",
    "        \"hidden_scale\": best_hidden,\n",
    "        \"news_alpha\": best_alpha,\n",
    "        \"learning_rate\": best_lr,\n",
    "        \"weight_decay\": best_wd,\n",
    "        \"label_smoothing\": best_smooth,\n",
    "    },\n",
    "    \"test_metrics\": test_metrics,\n",
    "    \"baseline_metrics\": baseline_test,\n",
    "}\n",
    "\n",
    "# Save results\n",
    "pd.DataFrame(arch_results).to_parquet(\"data/hyperparam_arch_results.pqt\")\n",
    "pd.DataFrame(train_results).to_parquet(\"data/hyperparam_train_results.pqt\")\n",
    "print(\"Saved search results to data/hyperparam_*.pqt\")\n",
    "\n",
    "# Save best model\n",
    "torch.save({\n",
    "    \"model_state_dict\": final_model.state_dict(),\n",
    "    \"config\": final_config,\n",
    "    \"price_cols\": price_feat_cols,\n",
    "    \"fund_cols\": fund_feat_cols,\n",
    "    \"emb_cols\": emb_cols,\n",
    "    \"training_approach\": \"simple_returns_no_clip\",  # Key change\n",
    "    \"search_results\": all_results,\n",
    "    \"test_metrics\": test_metrics,\n",
    "}, \"data/model_simple_returns.pt\")\n",
    "\n",
    "print(\"Saved best model to data/model_simple_returns.pt\")\n",
    "print(\"\\nNote: This model was trained on SIMPLE returns (not log) and evaluated WITHOUT clipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923cdf4f-3dd5-4c38-b8c8-c847c69f186d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a640fcbb-0008-4137-afd5-e5fef17001e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9650a945-33ed-425f-9b30-9760cef0994e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
